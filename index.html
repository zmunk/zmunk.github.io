<html>

<head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <style type="text/css">
    @import url('https://themes.googleusercontent.com/fonts/css?kit=eqLbnA_Efv82onanYUscTg');

    .lst-kix_hhnnp2o6wu1x-3>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-4>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-0>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-5>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-1>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-2>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-7>li:before {
        content: "-  "
    }

    ul.lst-kix_2hpuy1bprq1-8 {
        list-style-type: none
    }

    .lst-kix_hhnnp2o6wu1x-0>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-3>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-4>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-5>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-6>li:before {
        content: "-  "
    }

    ul.lst-kix_jwbte93xw3td-0 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-4 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-3 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-2 {
        list-style-type: none
    }

    .lst-kix_hhnnp2o6wu1x-8>li:before {
        content: "-  "
    }

    ul.lst-kix_jwbte93xw3td-1 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-8 {
        list-style-type: none
    }

    .lst-kix_kevuw7nat4u0-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_jwbte93xw3td-7 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-6 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-5 {
        list-style-type: none
    }

    .lst-kix_kevuw7nat4u0-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_kevuw7nat4u0-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_mbq35qj9hsqb-1>li:before {
        content: "-  "
    }

    .lst-kix_ca89skfh28u5-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_kevuw7nat4u0-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_kevuw7nat4u0-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_ca89skfh28u5-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_ca89skfh28u5-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_ca89skfh28u5-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_muss065vu37-1>li {
        counter-increment: lst-ctn-kix_muss065vu37-1
    }

    .lst-kix_ca89skfh28u5-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_kevuw7nat4u0-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_kevuw7nat4u0-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_kevuw7nat4u0-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_ca89skfh28u5-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_s3183918wdsy-1>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-1
    }

    .lst-kix_kevuw7nat4u0-0>li:before {
        content: "\0025cf  "
    }

    ol.lst-kix_s3183918wdsy-0.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-0 0
    }

    .lst-kix_hhnnp2o6wu1x-2>li:before {
        content: "-  "
    }

    .lst-kix_ca89skfh28u5-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_41hc7a3xqlgz-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_41hc7a3xqlgz-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_41hc7a3xqlgz-1 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-5.start {
        counter-reset: lst-ctn-kix_muss065vu37-5 0
    }

    ul.lst-kix_41hc7a3xqlgz-0 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-3 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-2 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-5 {
        list-style-type: none
    }

    .lst-kix_41hc7a3xqlgz-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_41hc7a3xqlgz-1>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_41hc7a3xqlgz-4 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-7 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-6 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-8 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-1 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-0 {
        list-style-type: none
    }

    .lst-kix_41hc7a3xqlgz-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_41hc7a3xqlgz-5>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_2hpuy1bprq1-3 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-2 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-5 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-5.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-5 0
    }

    ul.lst-kix_2hpuy1bprq1-4 {
        list-style-type: none
    }

    .lst-kix_41hc7a3xqlgz-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_41hc7a3xqlgz-6>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_2hpuy1bprq1-7 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-6 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-5>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-5
    }

    .lst-kix_s3183918wdsy-8>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-8
    }

    .lst-kix_41hc7a3xqlgz-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_7mmhsfv5wlqq-1>li:before {
        content: "-  "
    }

    .lst-kix_7mmhsfv5wlqq-7>li:before {
        content: "-  "
    }

    .lst-kix_7mmhsfv5wlqq-5>li:before {
        content: "-  "
    }

    ul.lst-kix_mbq35qj9hsqb-6 {
        list-style-type: none
    }

    .lst-kix_7mmhsfv5wlqq-3>li:before {
        content: "-  "
    }

    ul.lst-kix_mbq35qj9hsqb-5 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-4 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-3 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-8 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-7 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-4>li {
        counter-increment: lst-ctn-kix_muss065vu37-4
    }

    ol.lst-kix_s3183918wdsy-7.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-7 0
    }

    ul.lst-kix_mbq35qj9hsqb-2 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-1 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-3.start {
        counter-reset: lst-ctn-kix_muss065vu37-3 0
    }

    ul.lst-kix_mbq35qj9hsqb-0 {
        list-style-type: none
    }

    .lst-kix_bzf39rp48c5-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_bzf39rp48c5-1>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_7mmhsfv5wlqq-4 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-3 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-2 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-1 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-8 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-7 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-6 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-5 {
        list-style-type: none
    }

    .lst-kix_bzf39rp48c5-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_bzf39rp48c5-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_7mmhsfv5wlqq-0 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-0.start {
        counter-reset: lst-ctn-kix_muss065vu37-0 0
    }

    .lst-kix_up8f87x9hiuk-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_up8f87x9hiuk-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_up8f87x9hiuk-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_s3183918wdsy-4>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-4
    }

    .lst-kix_up8f87x9hiuk-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_ca89skfh28u5-7>li:before {
        content: "\0025cb  "
    }

    ol.lst-kix_s3183918wdsy-8 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-6 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-7 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-4 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-5 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-2 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-3 {
        list-style-type: none
    }

    .lst-kix_up8f87x9hiuk-2>li:before {
        content: "\0025a0  "
    }

    ol.lst-kix_s3183918wdsy-0 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-1 {
        list-style-type: none
    }

    .lst-kix_mbq35qj9hsqb-8>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-6>li:before {
        content: "-  "
    }

    .lst-kix_muss065vu37-5>li {
        counter-increment: lst-ctn-kix_muss065vu37-5
    }

    ul.lst-kix_kevuw7nat4u0-1 {
        list-style-type: none
    }

    .lst-kix_nj0r7j4h9jqu-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_kevuw7nat4u0-0 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-0 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-8>li:before {
        content: "-  "
    }

    .lst-kix_nj0r7j4h9jqu-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_nj0r7j4h9jqu-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_s3183918wdsy-2>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-2
    }

    .lst-kix_s3183918wdsy-1>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-1, lower-roman) ") "
    }

    ul.lst-kix_k90m6otahfkd-6 {
        list-style-type: none
    }

    .lst-kix_nj0r7j4h9jqu-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_csnx2t6mi4dz-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_k90m6otahfkd-5 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-0 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-8 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-2>li:before {
        content: "-  "
    }

    ul.lst-kix_k90m6otahfkd-8 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-7 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-7 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-6 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-0>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-0, lower-latin) ") "
    }

    ul.lst-kix_k90m6otahfkd-2 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-5 {
        list-style-type: none
    }

    .lst-kix_csnx2t6mi4dz-2>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_k90m6otahfkd-1 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-4 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-1>li:before {
        content: "-  "
    }

    ul.lst-kix_k90m6otahfkd-4 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-3 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-3 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-2 {
        list-style-type: none
    }

    .lst-kix_csnx2t6mi4dz-7>li:before {
        content: "\0025cb  "
    }

    ol.lst-kix_muss065vu37-7.start {
        counter-reset: lst-ctn-kix_muss065vu37-7 0
    }

    .lst-kix_csnx2t6mi4dz-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_o3r0171bkekx-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_jwbte93xw3td-5>li:before {
        content: "\0025a0  "
    }

    ol.lst-kix_muss065vu37-6.start {
        counter-reset: lst-ctn-kix_muss065vu37-6 0
    }

    .lst-kix_o3r0171bkekx-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_o3r0171bkekx-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_jwbte93xw3td-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_jwbte93xw3td-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_o3r0171bkekx-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_jwbte93xw3td-2>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_pw561kwiw4m0-5 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-6 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-7 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-8 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-0 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-1 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-2 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-3 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-4 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-7 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-8 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-5 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-6 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-3 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-4 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-1 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-2 {
        list-style-type: none
    }

    .lst-kix_o3r0171bkekx-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_7mmhsfv5wlqq-2>li:before {
        content: "-  "
    }

    ul.lst-kix_csnx2t6mi4dz-1 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-2 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-3 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-4 {
        list-style-type: none
    }

    .lst-kix_7mmhsfv5wlqq-6>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-7>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-7
    }

    ul.lst-kix_csnx2t6mi4dz-0 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-5 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-6 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-7 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-8 {
        list-style-type: none
    }

    .lst-kix_yp1d32cd33ka-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_bzf39rp48c5-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_bzf39rp48c5-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_up8f87x9hiuk-5>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_nj0r7j4h9jqu-8 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-7 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-8>li {
        counter-increment: lst-ctn-kix_muss065vu37-8
    }

    .lst-kix_w9ka78va5rsi-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_ca89skfh28u5-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_upn6eul5dnav-8>li:before {
        content: "-  "
    }

    .lst-kix_up8f87x9hiuk-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_w9ka78va5rsi-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_s3183918wdsy-0>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-0
    }

    .lst-kix_s3183918wdsy-8>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-8, decimal) ". "
    }

    .lst-kix_muss065vu37-7>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-7, lower-latin) ". "
    }

    .lst-kix_mbq35qj9hsqb-7>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-4>li:before {
        content: "("counter(lst-ctn-kix_s3183918wdsy-4, lower-roman) ") "
    }

    ol.lst-kix_muss065vu37-8.start {
        counter-reset: lst-ctn-kix_muss065vu37-8 0
    }

    ul.lst-kix_nj0r7j4h9jqu-4 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-3 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-6 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-5 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-0 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-5>li:before {
        content: "-  "
    }

    ul.lst-kix_nj0r7j4h9jqu-2 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-1 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-3>li:before {
        content: "("counter(lst-ctn-kix_muss065vu37-3, decimal) ") "
    }

    .lst-kix_k90m6otahfkd-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-8>li:before {
        content: "\0025a0  "
    }

    ol.lst-kix_muss065vu37-4.start {
        counter-reset: lst-ctn-kix_muss065vu37-4 0
    }

    .lst-kix_pw561kwiw4m0-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_k90m6otahfkd-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_pw561kwiw4m0-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_pw561kwiw4m0-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_k90m6otahfkd-4>li:before {
        content: "\0025cb  "
    }

    ol.lst-kix_s3183918wdsy-6.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-6 0
    }

    .lst-kix_pw561kwiw4m0-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_muss065vu37-0>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-0, decimal) ") "
    }

    .lst-kix_gp1ibqp1zuuw-2>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_gp1ibqp1zuuw-3>li:before {
        content: "-  "
    }

    .lst-kix_k90m6otahfkd-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_pw561kwiw4m0-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_gp1ibqp1zuuw-4>li:before {
        content: "-  "
    }

    .lst-kix_gp1ibqp1zuuw-6>li:before {
        content: "-  "
    }

    .lst-kix_k90m6otahfkd-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_pw561kwiw4m0-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_gp1ibqp1zuuw-5>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_gp1ibqp1zuuw-8>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_gp1ibqp1zuuw-7>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-3>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-3
    }

    .lst-kix_upn6eul5dnav-0>li:before {
        content: "-  "
    }

    ul.lst-kix_o3r0171bkekx-0 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-8>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-5>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-6>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-7>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-4>li:before {
        content: "-  "
    }

    .lst-kix_gp1ibqp1zuuw-1>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-3>li:before {
        content: "-  "
    }

    .lst-kix_gp1ibqp1zuuw-0>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-1>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-2>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-0>li:before {
        content: "-  "
    }

    ul.lst-kix_gp1ibqp1zuuw-6 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-5 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-4 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-3 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-3>li {
        counter-increment: lst-ctn-kix_muss065vu37-3
    }

    ul.lst-kix_gp1ibqp1zuuw-8 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-7 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-4>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-2>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-6>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_gp1ibqp1zuuw-2 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-1 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-1>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-5>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-6>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_gp1ibqp1zuuw-0 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-2 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-1 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-4 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-3 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-6 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-5 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-8 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-3>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_o3r0171bkekx-7 {
        list-style-type: none
    }

    .lst-kix_yp1d32cd33ka-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_yp1d32cd33ka-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_yp1d32cd33ka-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_w9ka78va5rsi-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_upn6eul5dnav-3 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-1 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-2 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-2 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-5 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-3 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-4 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-4 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-5 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-6 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-6>li {
        counter-increment: lst-ctn-kix_muss065vu37-6
    }

    ul.lst-kix_upn6eul5dnav-1 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-7 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-0 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-8 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-0 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-2 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-3 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-0 {
        list-style-type: none
    }

    .lst-kix_w9ka78va5rsi-1>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_mbzrtzx2wb9v-1 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-6 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-7 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-4 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-5 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-7 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-6 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-8 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-8 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-2.start {
        counter-reset: lst-ctn-kix_muss065vu37-2 0
    }

    .lst-kix_upn6eul5dnav-7>li:before {
        content: "-  "
    }

    .lst-kix_w9ka78va5rsi-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_w9ka78va5rsi-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_hhnnp2o6wu1x-5 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-6 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-3 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-4 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-6>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-6, decimal) ". "
    }

    .lst-kix_muss065vu37-8>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-8, lower-roman) ". "
    }

    ul.lst-kix_hhnnp2o6wu1x-7 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-8 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-7>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-7, lower-roman) ". "
    }

    .lst-kix_muss065vu37-2>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-2, lower-roman) ") "
    }

    .lst-kix_muss065vu37-4>li:before {
        content: "("counter(lst-ctn-kix_muss065vu37-4, lower-latin) ") "
    }

    ul.lst-kix_hhnnp2o6wu1x-1 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-2 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-0 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-5>li:before {
        content: "("counter(lst-ctn-kix_s3183918wdsy-5, decimal) ") "
    }

    ol.lst-kix_s3183918wdsy-8.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-8 0
    }

    .lst-kix_s3183918wdsy-3>li:before {
        content: "("counter(lst-ctn-kix_s3183918wdsy-3, lower-latin) ") "
    }

    .lst-kix_csnx2t6mi4dz-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_2hpuy1bprq1-6>li:before {
        content: "-  "
    }

    .lst-kix_2hpuy1bprq1-7>li:before {
        content: "-  "
    }

    .lst-kix_2hpuy1bprq1-4>li:before {
        content: "-  "
    }

    .lst-kix_muss065vu37-0>li {
        counter-increment: lst-ctn-kix_muss065vu37-0
    }

    .lst-kix_nj0r7j4h9jqu-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_2hpuy1bprq1-3>li:before {
        content: "-  "
    }

    .lst-kix_nj0r7j4h9jqu-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_csnx2t6mi4dz-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_nj0r7j4h9jqu-8>li:before {
        content: "\0025a0  "
    }

    ol.lst-kix_muss065vu37-1.start {
        counter-reset: lst-ctn-kix_muss065vu37-1 0
    }

    .lst-kix_csnx2t6mi4dz-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_2hpuy1bprq1-0>li:before {
        content: "-  "
    }

    ul.lst-kix_ca89skfh28u5-0 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-1 {
        list-style-type: none
    }

    .lst-kix_csnx2t6mi4dz-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_nj0r7j4h9jqu-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_csnx2t6mi4dz-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_nj0r7j4h9jqu-4>li:before {
        content: "\0025cb  "
    }

    ol.lst-kix_s3183918wdsy-3.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-3 0
    }

    ul.lst-kix_yp1d32cd33ka-0 {
        list-style-type: none
    }

    .lst-kix_o3r0171bkekx-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_o3r0171bkekx-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_jwbte93xw3td-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_bzf39rp48c5-0 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-1 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-2 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-3 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-4 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_yp1d32cd33ka-5 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-6 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-7 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-8 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-8 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-7 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-6 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-5 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-4 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-3 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-2 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_jwbte93xw3td-4>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_bzf39rp48c5-1 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-3>li:before {
        content: "\0025cf  "
    }

    ol.lst-kix_s3183918wdsy-4.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-4 0
    }

    .lst-kix_muss065vu37-7>li {
        counter-increment: lst-ctn-kix_muss065vu37-7
    }

    ul.lst-kix_ca89skfh28u5-2 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-3 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-4 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-5 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-6 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-7 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-8 {
        list-style-type: none
    }

    .lst-kix_7mmhsfv5wlqq-8>li:before {
        content: "-  "
    }

    .lst-kix_o3r0171bkekx-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_o3r0171bkekx-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_7mmhsfv5wlqq-0>li:before {
        content: "-  "
    }

    .lst-kix_7mmhsfv5wlqq-4>li:before {
        content: "-  "
    }

    .lst-kix_bzf39rp48c5-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_s3183918wdsy-6>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-6
    }

    .lst-kix_w9ka78va5rsi-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_yp1d32cd33ka-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_bzf39rp48c5-0>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_w9ka78va5rsi-1 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-0 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-3 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-2 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-5 {
        list-style-type: none
    }

    .lst-kix_bzf39rp48c5-4>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_w9ka78va5rsi-4 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-7 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-6 {
        list-style-type: none
    }

    .lst-kix_yp1d32cd33ka-0>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_w9ka78va5rsi-8 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-1.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-1 0
    }

    .lst-kix_w9ka78va5rsi-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_up8f87x9hiuk-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_w9ka78va5rsi-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_up8f87x9hiuk-3>li:before {
        content: "\0025cf  "
    }

    ol.lst-kix_s3183918wdsy-2.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-2 0
    }

    .lst-kix_s3183918wdsy-6>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-6, lower-latin) ". "
    }

    .lst-kix_muss065vu37-2>li {
        counter-increment: lst-ctn-kix_muss065vu37-2
    }

    .lst-kix_muss065vu37-1>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-1, lower-latin) ") "
    }

    .lst-kix_muss065vu37-5>li:before {
        content: "("counter(lst-ctn-kix_muss065vu37-5, lower-roman) ") "
    }

    .lst-kix_s3183918wdsy-2>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-2, decimal) ") "
    }

    ol {
        margin: 0;
        padding: 0
    }

    table td,
    table th {
        padding: 0
    }

    .c23 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 24pt;
        line-height: 1.0;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: right
    }

    .c26 {
        margin-left: 45pt;
        padding-top: 18pt;
        padding-bottom: 4pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c12 {
        margin-left: 18pt;
        padding-top: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c21 {
        margin-left: 27pt;
        padding-top: 15pt;
        padding-bottom: 3pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c30 {
        margin-left: 18pt;
        padding-top: 10pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c40 {
        margin-left: 27pt;
        padding-top: 10pt;
        padding-bottom: 3pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c19 {
        margin-left: 72pt;
        padding-top: 0pt;
        padding-left: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c11 {
        margin-left: 72pt;
        padding-top: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left;
        height: 11pt
    }

    .c17 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 10pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: center
    }

    .c10 {
        margin-left: 27pt;
        padding-top: 12pt;
        padding-bottom: 3pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c0 {
        margin-left: 18pt;
        padding-top: 12pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c1 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c29 {
        color: #666666;
        font-weight: 400;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 11pt;
        font-family: "Georgia";
        font-style: normal
    }

    .c28 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 24pt;
        font-family: "Lora";
        font-style: normal
    }

    .c4 {
        color: #666666;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 12pt;
        font-family: "Lora";
        font-style: normal
    }

    .c6 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 10pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c35 {
        color: #000000;
        font-weight: 400;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 14pt;
        font-family: "Georgia";
        font-style: normal
    }

    .c36 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 18pt;
        font-family: "Lora";
        font-style: normal
    }

    .c27 {
        padding-top: 0pt;
        padding-left: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c2 {
        color: #000000;
        font-weight: 400;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 11pt;
        font-family: "Georgia";
        font-style: normal
    }

    .c34 {
        color: #000000;
        font-weight: 400;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 24pt;
        font-family: "Georgia";
        font-style: normal
    }

    .c5 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 13pt;
        font-family: "Lora";
        font-style: normal
    }

    .c14 {
        padding-top: 12pt;
        padding-bottom: 4pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c18 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 15pt;
        font-family: "Lora";
        font-style: normal
    }

    .c32 {
        padding-top: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c20 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        font-size: 15pt;
        font-family: "Lora";
        font-style: normal
    }

    .c7 {
        color: #000000;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 11pt;
        font-style: normal
    }

    .c37 {
        color: #999999;
        text-decoration: none;
        vertical-align: baseline;
        font-style: italic
    }

    .c9 {
        text-decoration-skip-ink: none;
        -webkit-text-decoration-skip: none;
        color: #1155cc;
        text-decoration: underline
    }

    .c22 {
        background-color: #ffffff;
        max-width: 468pt;
        padding: 72pt 72pt 72pt 72pt
    }

    .c31 {
        font-weight: 400;
        font-size: 11pt;
        font-family: "Georgia"
    }

    .c13 {
        color: inherit;
        text-decoration: inherit
    }

    .c33 {
        padding: 0;
        margin: 0
    }

    .c3 {
        font-weight: 400;
        font-family: "Courier New"
    }

    .c38 {
        font-style: italic;
        color: #999999
    }

    .c39 {
        color: #000000
    }

    .c16 {
        vertical-align: sub
    }

    .c41 {
        font-style: italic
    }

    .c15 {
        height: 11pt
    }

    .c8 {
        vertical-align: super
    }

    .c24 {
        margin-left: 36pt
    }

    .c25 {
        background-color: #ffff00
    }

    .title {
        padding-top: 0pt;
        color: #000000;
        font-size: 26pt;
        padding-bottom: 3pt;
        font-family: "Georgia";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .subtitle {
        padding-top: 0pt;
        color: #666666;
        font-size: 15pt;
        padding-bottom: 16pt;
        font-family: "Arial";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    li {
        color: #000000;
        font-size: 11pt;
        font-family: "Georgia"
    }

    p {
        margin: 0;
        color: #000000;
        font-size: 11pt;
        font-family: "Georgia"
    }

    h1 {
        padding-top: 18pt;
        color: #000000;
        font-weight: 700;
        font-size: 18pt;
        padding-bottom: 4pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h2 {
        padding-top: 12pt;
        color: #000000;
        font-weight: 700;
        font-size: 15pt;
        padding-bottom: 3pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h3 {
        padding-top: 12pt;
        color: #000000;
        font-weight: 700;
        font-size: 13pt;
        padding-bottom: 0pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h4 {
        padding-top: 0pt;
        color: #666666;
        font-weight: 700;
        font-size: 12pt;
        padding-bottom: 0pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h5 {
        padding-top: 12pt;
        color: #666666;
        font-size: 11pt;
        padding-bottom: 4pt;
        font-family: "Georgia";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h6 {
        padding-top: 12pt;
        color: #666666;
        font-size: 11pt;
        padding-bottom: 4pt;
        font-family: "Georgia";
        line-height: 1.15;
        page-break-after: avoid;
        font-style: italic;
        orphans: 2;
        widows: 2;
        text-align: left
    }
    </style>
</head>

<body class="c22">
    <p>updated: 8:45 pm</p>
    <p class="c17 title" id="h.af2d0hbx4i0d"><span class="c28">Computer Vision Midterm Study Guide</span></p>
    <p class="c23 subtitle"><span class="c31 c38">Ibrahim Tigrek</span></p>
    <h1 class="c26" id="h.abbw2mu8xyt2"><span class="c36">Important Topics</span></h1>
    <h2 class="c10" id="h.z7hkcegwwwg5"><span>Cross-Validation</span><span class="c8 c20">2.2</span></h2>
    <h4 class="c12" id="h.h8q0hqpuyym"><span class="c4">Purpose</span></h4>
    <p class="c1"><span>The purpose of cross validation is t</span><span>o determine the optimum values of the hyperparameters, which are </span><span class="c2">the parameters that are set for the algorithm.</span></p>
    <p class="c1"><span>k-</span><span>fold cross-validation is performed by dividing the training set into k sets, each one called a fold. Let&rsquo;s take k = 5, which is what is usually used. First, we train a model with a certain set of hyperparameters on the first 4 folds, and validate it (i.e. test it) on the 5th fold. Then we do the same, but this time the </span><span class="c41">validation set</span><span class="c2">&nbsp;is the 4th fold. Then again with the 3rd fold, and so on for all 5 possible combinations. For each of these iterations, we get a performance measure. We average these to get the final performance measure of the model with this specific set of hyperparameters.</span></p>
    <p class="c1"><span class="c2">We do all of this again for another model, that has a different set of hyperparameters. And again for another model, and so on. Once we are satisfied with all the combinations of hyperparameters that we have validated, we choose the model that gave us the best overall performance measure. Then, and only then, do we use the test data, to test our final model.</span></p>
    <p class="c1 c15"><span class="c2"></span></p>
    <h2 class="c10" id="h.r9s32jnwg1t2"><span class="c18">Regularization</span></h2>
    <p class="c1"><span class="c2">Strength of regularization depends on the hyperparameter &lambda;.</span></p>
    <p class="c1"><span class="c2">Regularization makes the model simpler, and spreads out the weights.</span></p>
    <p class="c1"><span class="c2">When building neural networks, it is recommended to start with as many neurons as the computer can handle, and apply regularization.</span></p>
    <h4 class="c12" id="h.nlfknrw5d073"><span class="c4">L1 regularization</span></h4>
    <p class="c1"><img src="images/image1.png"></p>
    <p class="c1"><span class="c2">Also called Lasso regression. Lasso regression usually reduces useless features to zero.</span></p>
    <h4 class="c12" id="h.bygdaau62vgc"><span class="c4">L2 regularization</span></h4>
    <p class="c1"><span>is differentiable.</span></p>
    <p class="c1"><img src="images/image2.png"></p>
    <p class="c1"><span class="c2">Also called Ridge regression.</span></p>
    <h4 class="c12" id="h.7h2s7e9uoife"><span class="c4">Elastic net regularization</span></h4>
    <p class="c1"><span class="c2">Is a combination of lasso and ridge regression. A hyperparameter (r) determines how much of lasso and ridge are used. </span></p>
    <p class="c1"><img src="images/image3.png"></p>
    <p class="c1 c15"><span class="c2"></span></p>
    <h4 class="c12" id="h.hv0e50arnb62"><span class="c4">Max norm constraints</span></h4>
    <p class="c1"><span class="c2">Ensures that the norm of all of the weights is less than a specified bound. This is to prevent the neurons from becoming saturated.</span></p>
    <h4 class="c12" id="h.r1tdi9pfjerc"><span class="c4">Dropout regularization</span></h4>
    <p class="c1"><span class="c2">Starting with a fully-connected neural network, some neurons are killed off randomly based on a predefined probability. The &ldquo;killing&rdquo; of the neurons is done by cutting off all of the input to that neuron.</span></p>
    <p class="c1"><span class="c2">Dropout regularization is used to weaken the strength of the network, thus making it harder for it to memorize the training data.</span></p>
    <h4 class="c12" id="h.ns610z1abd2l"><span class="c4">Noise</span></h4>
    <h4 class="c12" id="h.ns610z1abd2l-1"><span class="c4">Bias regularization</span></h4>
    <h4 class="c12" id="h.ns610z1abd2l-2"><span class="c4">per-layer regularization</span></h4>
    <p class="c1 c15"><span class="c2"></span></p>
    <h2 class="c10" id="h.441g8zed6ppz"><span class="c18">Gradient Descent</span></h2>
    <p class="c1"><span class="c2">For every weight, the partial derivative of the loss function with respect to that weight is determined. Then, that weight is decreased by the product of the step size and the gradient (the partial derivative).</span></p>
    <p class="c1"><img src="images/image4.png"></p>
    <h4 class="c12" id="h.obubqvsecfde"><span class="c4">Mini-batch gradient descent</span></h4>
    <p class="c1"><span class="c2">A small group of data points (e.g. 128) are used to determine the gradient.</span></p>
    <h4 class="c12" id="h.dy6v9bqvexpv"><span class="c4">Stochastic gradient descent</span></h4>
    <p class="c1"><span class="c2">The gradient is calculated and a step is taken for single data point. The data point in question is chosen randomly from the full dataset.</span></p>
    <p class="c1 c15"><span class="c2"></span></p>
    <p class="c1"><span class="c2">Numerical gradient</span></p>
    <p class="c1"><span class="c2">Analytic gradient</span></p>
    <p class="c1"><span class="c2">Mini-batch</span></p>
    <p class="c1"><span class="c2">stochastic</span></p>
    <p class="c1"><span class="c2">step size</span></p>
    <h2 class="c10" id="h.8e95tcb8x7px"><span class="c18">Back-propagation</span></h2>
    <h4 class="c12" id="h.a642lt558l5g"><span class="c4">The Algorithm</span></h4>
    <p class="c1"><span>Each node is examined independently, where only the input values, the output value, and the gradient propagating back to this node are necessary. Let&rsquo;s call our node N, and the two inputs x and y. Let&rsquo;s call the function at this node f, where f produces the output of this node from x and y, i.e. the output is f(x, y). Finally, let&rsquo;s call the gradient that has propagated back to N from the next node, d. It is our job to compute the gradients d</span><span class="c16">x</span><span>&nbsp;and d</span><span class="c16">y</span><span>, which are the gradients that N will propagate back to the nodes before it, where d</span><span class="c16">x</span><span>&nbsp;will go back along the path that brought x to N, and d</span><span class="c16">y</span><span class="c2">&nbsp;similarly for y.</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">x</span><span class="c7 c3">&nbsp;= d * f&rsquo;(x)</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">y</span><span class="c7 c3">&nbsp;= d * f&rsquo;(y)</span></p>
    <p class="c1"><span>where </span><span class="c3">f&rsquo; </span><span>is the partial derivative of f with respect to the argument. If, when computing </span><span class="c3">f&rsquo;(x)</span><span class="c2">, the function contains the variable y, then the value of the input in that specific case is used.</span></p>
    <h4 class="c12" id="h.a9thrik9xptw"><span class="c4">Patterns</span></h4>
    <p class="c1"><span class="c2">On some gates (nodes) have simple interpretations.</span></p>
    <h5 class="c14" id="h.99dlv3tzqom9"><span class="c29">Add gate</span></h5>
    <p class="c1"><span class="c2">f(x, y) = x + y</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">x</span><span class="c7 c3">&nbsp;= d</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">y</span><span class="c7 c3">&nbsp;= d</span></p>
    <h5 class="c14" id="h.2etqda1u6txk"><span class="c29">Max gate</span></h5>
    <p class="c1"><span class="c2">f(x, y) = max(x, y), assuming x &gt; y,</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">x</span><span class="c7 c3">&nbsp;= d</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">y</span><span class="c3 c7">&nbsp;= 0</span></p>
    <h5 class="c14" id="h.2ysxt030sj3t"><span class="c29">Multiply gate</span></h5>
    <p class="c1"><span class="c2">f(x, y) = x * y</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">x</span><span class="c7 c3">&nbsp;= d * y</span></p>
    <p class="c1"><span class="c3">d</span><span class="c3 c16">y</span><span class="c3">&nbsp;= d * x</span></p>
    <h2 class="c10" id="h.460fkihq20vk"><span>Linear Classification</span><span class="c31 c8">2.2</span></h2>
    <p class="c1"><span class="c2">There are no hidden layers in the neural network.</span></p>
    <p class="c1"><span class="c2">- More powerful than KNN and it doesn&#39;t memorize the data it is less expensive in computation as it uses only one image calculation instead of comparing it with all the training images. </span></p>
    <p class="c1"><span class="c2">- We will need the score function to map row data to class score and a loss function to calculate the difference between the predicted score and the truth labels &nbsp;.</span></p>
    <p class="c1 c15"><span class="c2"></span></p>
    <p class="c1"><span class="c2">- the score function :</span></p>
    <p class="c1 c15"><span class="c2"></span></p>
    <p class="c1 c24"><span class="c2">a) xi&isin;RD &nbsp;xi images with labels yi....N</span></p>
    <p class="c1 c24"><span class="c2">b) yi&isin;1&hellip;K &nbsp; labels are element of range 1...K</span></p>
    <p class="c1 c24"><span class="c2">c) if we have N examples of dimension &nbsp;and Categories K</span></p>
    <p class="c1 c24"><span class="c2">d) &nbsp;the score function f:RD&#8614;RK</span></p>
    <p class="c1 c24"><span class="c2">example CIFAR 10 K = 10 categories</span></p>
    <p class="c1 c24"><span class="c2">N = 50K &nbsp;and D = 32*32*3 pixels</span></p>
    <p class="c1 c15 c24"><span class="c2"></span></p>
    <ul class="c33 lst-kix_2hpuy1bprq1-0 start">
        <li class="c27 c24"><span class="c2">Linear classifier : </span></li>
    </ul>
    <ol class="c33 lst-kix_s3183918wdsy-0 start" start="1">
        <li class="c19"><span class="c2">Flatten the images xi to the vector b[K*1] </span></li>
        <li class="c19"><span class="c2">The matrix W[D*K] &nbsp;and the vector b[K*1] &nbsp;are the parameter </span></li>
        <li class="c19"><span class="c2">f(xi,W,b) = Wxi + b</span></li>
        <li class="c19"><span class="c2">W is the weight parameter and b is the bias vector </span></li>
        <li class="c19"><span class="c2">(xi ,yi) &nbsp;are fixed but we have control over (W,b) </span></li>
        <li class="c19"><span class="c2">Every row in W is a certain classifier. </span></li>
    </ol>
    <p class="c11"><span class="c2"></span></p>
    <h4 class="c12" id="h.wirufibgya9r"><span class="c4">Bias trick</span></h4>
    <p class="c1"><span>Usually, the input vector x, to a neuron, is fed through the following formula: </span><span class="c3">y = Wx + b</span><span>, where W is a matrix; y and b are vectors. But the bias trick allows us to use only one matrix without adding a bias separately; by concatenating W with b which creates </span><span class="c3">W&rsquo;</span><span>and adding 1 to the bottom of the x vector, creating</span><span class="c3">&nbsp;x&rsquo;.</span><span>&nbsp;So, we get the same y as earlier by</span><span class="c3">&nbsp;y = W&rsquo; * x&rsquo;.</span></p>
    <h4 class="c12" id="h.9vn6elcnwkqb"><span class="c4">Softmax classifier</span></h4>
    <p class="c1"><span class="c2">(Multinomial Logistic Regression)</span></p>
    <p class="c1"><span class="c2">This classifier gives the probability of each class label based on the softmax function. (see softmax loss function)</span></p>
    <p class="c1"><span class="c2">When the number of labels is really large, a variation of softmax, called &ldquo;hierarchical softmax&rdquo;, is used, since it is faster to evaluate.</span></p>
    <h1 class="c26" id="h.vj9f20camcvs"><span class="c36">Related Topics</span></h1>
    <h2 class="c10" id="h.xlehv8hw21ad"><span class="c18">Perceptron</span></h2>
    <p class="c6"><span>A</span><span class="c31 c39">&nbsp;network consisting of inputs feeding into a single neuron </span><span>which has </span><span class="c31 c39">a step function as its activation function. Single p</span><span>erceptron wasn&rsquo;t enough to solve the XOR-problem. However, creating a hidden layer with two perceptrons can solve the problem.</span></p>
    <h2 class="c10" id="h.u3l6b5nyhh14"><span class="c18">Activation functions</span></h2>
    <h4 class="c12" id="h.34edzig8hemd"><span class="c4">step function</span></h4>
    <h4 class="c12" id="h.34edzig8hemd-3"><span class="c4">sigmoid function</span></h4>
    <h4 class="c12" id="h.34edzig8hemd-4"><span class="c4">hyperbolic tangent function</span></h4>
    <h4 class="c12" id="h.75wcoj949i5w"><span class="c4">relu (rectified linear unit) function</span></h4>
    <p class="c1"><span class="c2">Most commonly used in neural networks.</span></p>
    <h2 class="c10" id="h.i98ollver278"><span class="c18">Loss functions</span></h2>
    <p class="c1"><span class="c2">Consist of two parts: the error and the regularization. (see Regularization)</span></p>
    <h4 class="c12" id="h.y0ptdaf1jgin"><span class="c4">Multiclass SVM loss</span></h4>
    <p class="c1"><span>(S</span><span class="c16">j</span><span>) is the score of </span><span>j, and the &nbsp;</span><span>S</span><span class="c16">yi</span><span>&nbsp;is the true score of label y , and </span><img src="images/image5.png"><span class="c2">&nbsp;is the sum of the incorrect classes </span></p>
    <p class="c1"><img src="images/image6.png"><span class="c2">&nbsp; &nbsp; Note: safety margin here is 1.</span></p>
    <h4 class="c12" id="h.g3foklfps5wm"><span class="c4">Hinge loss</span></h4>
    <p class="c1 c15"><span class="c2"></span></p>
    <p class="c1"><img><span class="c2">&nbsp; where t=1, if 1 is the intended output.</span></p>
    <h4 class="c12" id="h.ng115ad76ez"><span class="c4">Softmax loss function</span></h4>
    <p class="c1"><img></p>
    <p class="c1"><span>where </span><img src="images/image7.png"></p>
    <h4 class="c12" id="h.mhz5ssbcueo5"><span class="c4">Log loss function</span></h4>
    <p class="c1"><img src="images/image8.png"></p>
    <p class="c1"><span>where </span><img src="images/image9.png"><span class="c2">&nbsp;is the output of the prediction fed through the sigmoid activation function.</span></p>
    <h4 class="c12" id="h.jsc83bjkdul7"><span class="c4">Cross entropy loss function</span></h4>
    <p class="c1"><img src="images/image10.png"></p>
    <h2 class="c10" id="h.qdngtzlobw9f"><span class="c18">Nearest neighbor classifier</span></h2>
    <p class="c1"><span class="c2">Memorizes all data and labels. Predicts the label of the closest data point. (see L1 and L2 distance)</span></p>
    <h2 class="c10" id="h.qt9qbjyo8ex0"><span>k-nearest neighbor classifier </span><span class="c8">2</span><span class="c8">.2</span></h2>
    <p class="c1"><span class="c2">KNN summary : - in image classification we start with the training set and labels and must predict labels on test sets</span></p>
    <p class="c1"><span class="c2">- the KNN classifier predict labels based on the nearest neighbors:</span></p>
    <p class="c1"><span class="c2">- distance metrics and K are the hyper-parameters choose this in the validation set.</span></p>
    <p class="c1"><span class="c2">Two different distances</span></p>
    <ol class="c33 lst-kix_muss065vu37-0 start" start="1">
        <li class="c24 c27"><span>Manhattan distance : </span><img src="images/image11.png"></li>
        <li class="c27 c24"><span>Euclidean distance : </span><img src="images/image12.png"></li>
    </ol>
    <p class="c1"><span class="c2">Predicts based on classes of majority of labels of k nearest neighbors. Odd number is used for k to prevent stalemate vote.</span></p>
    <p class="c1"><span>This classifier does no work to train.</span></p>
    <h2 class="c10" id="h.ljjiaff9bjy6"><span class="c18">Approximate nearest neighbor</span></h2>
    <p class="c1"><span class="c2">Gives a neighbor that is very likely to be the nearest neighbor but doesn&rsquo;t guarantee it.</span></p>
    <h2 class="c10" id="h.o0pqsn0uu7d"><span class="c18">Viewpoints</span></h2>
    <ul class="c33 lst-kix_hhnnp2o6wu1x-0 start">
        <li class="c27 c24"><span class="c2">algebraic</span></li>
        <li class="c27 c24"><span class="c2">visual</span></li>
        <li class="c27 c24"><span class="c2">geometric</span></li>
    </ul>
    <h2 class="c21" id="h.s6d5od5pkzlu"><span class="c18">Optimization</span></h2>
    <h4 class="c12" id="h.c5re9lng8m7i"><span class="c4">Strategies</span></h4>
    <p class="c1"><span>r</span><span class="c2">andom search</span></p>
    <p class="c1"><span class="c2">random local search</span></p>
    <p class="c1"><span class="c2">following the gradient (see gradient descent)</span></p>
    <h2 class="c10" id="h.ekdtc5tubypw"><span class="c18">Activation functions</span></h2>
    <p class="c1"><span class="c2">sigmoid</span></p>
    <p class="c1"><span class="c2">relu</span></p>
    <p class="c1"><span class="c2">hyperbolic tangent</span></p>
    <p class="c1"><span class="c2">leaky relu</span></p>
    <p class="c1"><span>maxout</span></p>
    <h2 class="c10" id="h.8x454o2fohmq"><span class="c18">Single neuron classifiers</span></h2>
    <p class="c1"><span class="c2">Binary softmax classifier</span></p>
    <p class="c6"><span class="c2">Binary SVM classifier</span></p>
    <h2 class="c40" id="h.5k3i3zsc20uw"><span class="c18">Data preprocessing</span></h2>
    <p class="c1"><span class="c2">mean subtraction</span></p>
    <p class="c1"><span class="c2">normalization</span></p>
    <p class="c1"><span class="c2">PCA (principal component analysis)</span></p>
    <h2 class="c40" id="h.n8u481e84pk6"><span class="c18">Weight initialization</span></h2>
    <h4 class="c12" id="h.8yjwux8cr6b5"><span class="c4">all zero initialization</span></h4>
    <p class="c1"><span class="c2">All the weights are initialized to zero. The downside is that this will cause all of them to undergo the same parameter updates. This means there is no asymmetry among the weights, making the network struggle to learn.</span></p>
    <h4 class="c12" id="h.2c5acm7or6c7"><span class="c4">small random numbers</span></h4>
    <p class="c1"><span class="c2">The weights of the neurons are all random and unique in the beginning, so they will compute distinct updates and integrate themselves as diverse parts of the full network. A problem is that the variance grows with the number of inputs.</span></p>
    <h4 class="c12" id="h.lnyd2mdsw9h1"><span class="c4">calibrating variances</span></h4>
    <p class="c1"><span class="c2">Compensates for the increasing variance by scaling each neurons weight vector by the square root of the number of inputs to that neuron.</span></p>
    <h4 class="c12" id="h.1mxrye7qj82z"><span class="c4">sparse initialization</span></h4>
    <h2 class="c10" id="h.l6e9b9ing0hj"><span class="c18">Bias initialization</span></h2>
    <p class="c1"><span class="c2">Zero-bias initialization works fine.</span></p>
    <h2 class="c10" id="h.1mxrye7qj82z-5"><span class="c18">Batch normalization</span></h2>
    <p class="c1"><span>Normalizing the output of a </span><span>layer</span><span class="c2">&nbsp;before passing it to the next layer. This is to ensure that the neurons don&rsquo;t get saturated.</span></p>
    <h2 class="c21" id="h.dtp51kmgxf13"><span class="c18">Overfitting and Underfitting</span></h2>
    <p class="c1"><span class="c2">The desired model is the one that is neither high bias nor high variance.</span></p>
    <h4 class="c12" id="h.ezjt1trs5k1b"><span class="c4">High-bias</span></h4>
    <p class="c1"><span class="c2">A model that is too simple is considered to have high bias and low variance. It is also called under-fitting.</span></p>
    <h4 class="c12" id="h.lzb4ugqwfjyz"><span class="c4">High-variance</span></h4>
    <p class="c1"><span class="c2">A model that is too complex is considered to have high variance and low bias. It is also called over-fitting.</span></p>
    <h2 class="c10" id="h.53sil47c1hok"><span class="c18">Saturation of a neuron</span></h2>
    <p class="c1"><span class="c2">This occurs when the output of a neuron is insensitive to the input, i.e. it is the same regardless of any changes to the input. This is considered a dead, or dying, neuron. This happens when the input value has become very large or very small (negative).</span></p>
    <h2 class="c10" id="h.dt7nchdtvn2a"><span class="c18">Additional topics</span></h2>
    <p class="c1"><span class="c2">L1 and L2 distance</span></p>
    <p class="c1"><span class="c2">binary cross entropy</span></p>
    <p class="c1"><span class="c2">L2 regression loss function</span></p>
    <p class="c1"><span class="c2">Hierarchical softmax</span></p>
    <p class="c1"><span class="c2">Momentum optimization</span></p>
    <p class="c1"><span class="c2">Stratified sampling</span></p>
    <p class="c1"><span class="c2">Vanishing gradient problem</span></p>
    <p class="c1"><span class="c2">SIFT (scale-invariant feature transform)</span></p>
    <p class="c1"><span class="c2">One-shot learning</span></p>
    <h1 class="c26" id="h.7jwdpdkaxu4t"><span class="c36">Appendix</span></h1>
    <h2 class="c10" id="h.se5mth9nayk6"><span class="c18">Main resources</span></h2>
    <h3 class="c0" id="h.j5ase9f9gh05"><span class="c5">Packt textbook Ch. 1 </span></h3>
    <p class="c6"><span class="c9 c31"><a class="c13" href="https://www.google.com/url?q=https://subscription.packtpub.com/book/data/9781788830645/1/ch01lvl1sec02/computer-vision-in-the-wild&amp;sa=D&amp;ust=1574275470386000">https://subscription.packtpub.com/book/data/9781788830645/1/ch01lvl1sec02/computer-vision-in-the-wild</a></span></p>
    <h3 class="c0" id="h.d3xip9nt8msq"><span class="c5">Stanford Neural Networks</span></h3>
    <h4 class="c12" id="h.o9b4myvpyvxc"><span class="c4">Main page</span></h4>
    <p class="c1"><span class="c8">2.1</span><span>&nbsp;</span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/&amp;sa=D&amp;ust=1574275470387000">http://cs231n.github.io/</a></span></p>
    <h4 class="c12" id="h.xj8p7u56q44h"><span class="c4">Classification</span></h4>
    <p class="c1"><span class="c8">2.2</span><span>&nbsp;</span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/classification/&amp;sa=D&amp;ust=1574275470387000">http://cs231n.github.io/classification/</a></span></p>
    <h4 class="c12" id="h.cxtmt6uu70eb"><span class="c4">Linear classification</span></h4>
    <p class="c1"><span class="c8">2.3 </span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/linear-classify/&amp;sa=D&amp;ust=1574275470388000">http://cs231n.github.io/linear-classify/</a></span></p>
    <h4 class="c12" id="h.og6hu97zmjo"><span class="c4">Optimization</span></h4>
    <p class="c1"><span class="c8">2.4 </span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/optimization-1/&amp;sa=D&amp;ust=1574275470388000">http://cs231n.github.io/optimization-1/</a></span></p>
    <h4 class="c12" id="h.a0bztbttu3gy"><span class="c4">Back-propagation</span></h4>
    <p class="c1"><span class="c8">2.5 </span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/optimization-2/&amp;sa=D&amp;ust=1574275470389000">http://cs231n.github.io/optimization-2/</a></span></p>
    <h4 class="c12" id="h.n765s5jmkrq2"><span class="c4">Neural networks part 1</span></h4>
    <p class="c1"><span class="c8">2.6 </span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/neural-networks-1/&amp;sa=D&amp;ust=1574275470389000">http://cs231n.github.io/neural-networks-1/</a></span></p>
    <h4 class="c12" id="h.dhkwmbz4e6js"><span class="c4">Neural networks part 2</span></h4>
    <p class="c1"><span class="c8">2.7 </span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/neural-networks-2/&amp;sa=D&amp;ust=1574275470389000">http://cs231n.github.io/neural-networks-2/</a></span></p>
    <h4 class="c12" id="h.h8r53vq8ynkt"><span class="c4">Neural networks part 3</span></h4>
    <p class="c1"><span class="c8">2.8 </span><span class="c9"><a class="c13" href="https://www.google.com/url?q=http://cs231n.github.io/neural-networks-3/&amp;sa=D&amp;ust=1574275470390000">http://cs231n.github.io/neural-networks-3/</a></span></p>
    <h3 class="c0" id="h.j3nb1l2cuezs"><span class="c5">Slides</span></h3>
    <p class="c6"><span>Neural networks representation: non-linear hypotheses (Andrew Ng, ML wk 4 lecture 8)</span></p>
    <h2 class="c10" id="h.x88b8s9lxwn5"><span class="c18">Additional resources</span></h2>
    <h4 class="c30" id="h.s6sc9sy44g3e"><span class="c4">create your own neural network</span></h4>
    <p class="c6"><span class="c2">playground.tensorflow.org</span></p>
    <h4 class="c30" id="h.qxl6s05ast2l"><span class="c4">k-nearest neighbors demo</span></h4>
    <p class="c6"><span class="c2">vision.stanford.edu</span></p>
    <h4 class="c30" id="h.wv6enpe6t7r1"><span class="c4">Linear Classification Demo</span></h4>
    <p class="c6"><span class="c9 c31"><a class="c13" href="https://www.google.com/url?q=http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/&amp;sa=D&amp;ust=1574275470391000">http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/</a></span></p>
    <h4 class="c30" id="h.xybo2n6f742e"><span class="c4">Code Words (not sure how it&rsquo;s connected exactly)</span></h4>
    <p class="c6"><span class="c2">codewords.recurse.com</span></p>
    <p class="c6 c15"><span class="c2"></span></p>
    <div>
        <p class="c15 c32"><span class="c2"></span></p>
    </div>
</body>

</html>