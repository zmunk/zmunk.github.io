<html>

<head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <style type="text/css">
    @import url('https://themes.googleusercontent.com/fonts/css?kit=eqLbnA_Efv82onanYUscTg');

    .lst-kix_hhnnp2o6wu1x-3>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-4>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-0>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-5>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-1>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-2>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-7>li:before {
        content: "-  "
    }

    ul.lst-kix_2hpuy1bprq1-8 {
        list-style-type: none
    }

    .lst-kix_hhnnp2o6wu1x-0>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-3>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-4>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-5>li:before {
        content: "-  "
    }

    .lst-kix_hhnnp2o6wu1x-6>li:before {
        content: "-  "
    }

    ul.lst-kix_lt578i1ly35g-8 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-0 {
        list-style-type: none
    }

    ul.lst-kix_lt578i1ly35g-7 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-4 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-3 {
        list-style-type: none
    }

    .lst-kix_hhnnp2o6wu1x-8>li:before {
        content: "-  "
    }

    ul.lst-kix_jwbte93xw3td-2 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-1 {
        list-style-type: none
    }

    ul.lst-kix_lt578i1ly35g-0 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-8 {
        list-style-type: none
    }

    .lst-kix_kevuw7nat4u0-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_jwbte93xw3td-7 {
        list-style-type: none
    }

    ul.lst-kix_lt578i1ly35g-2 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-6 {
        list-style-type: none
    }

    ul.lst-kix_lt578i1ly35g-1 {
        list-style-type: none
    }

    ul.lst-kix_jwbte93xw3td-5 {
        list-style-type: none
    }

    ul.lst-kix_lt578i1ly35g-4 {
        list-style-type: none
    }

    ul.lst-kix_lt578i1ly35g-3 {
        list-style-type: none
    }

    .lst-kix_kevuw7nat4u0-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_kevuw7nat4u0-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_mbq35qj9hsqb-1>li:before {
        content: "-  "
    }

    ul.lst-kix_lt578i1ly35g-6 {
        list-style-type: none
    }

    ul.lst-kix_lt578i1ly35g-5 {
        list-style-type: none
    }

    .lst-kix_ca89skfh28u5-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_kevuw7nat4u0-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_kevuw7nat4u0-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_ca89skfh28u5-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_ca89skfh28u5-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_ca89skfh28u5-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_muss065vu37-1>li {
        counter-increment: lst-ctn-kix_muss065vu37-1
    }

    .lst-kix_ca89skfh28u5-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_kevuw7nat4u0-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_kevuw7nat4u0-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_kevuw7nat4u0-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_ca89skfh28u5-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_s3183918wdsy-1>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-1
    }

    .lst-kix_kevuw7nat4u0-0>li:before {
        content: "\0025cf  "
    }

    ol.lst-kix_s3183918wdsy-0.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-0 0
    }

    .lst-kix_hhnnp2o6wu1x-2>li:before {
        content: "-  "
    }

    .lst-kix_ca89skfh28u5-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_41hc7a3xqlgz-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_41hc7a3xqlgz-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_lt578i1ly35g-5>li:before {
        content: "-  "
    }

    .lst-kix_lt578i1ly35g-4>li:before {
        content: "-  "
    }

    .lst-kix_lt578i1ly35g-6>li:before {
        content: "-  "
    }

    .lst-kix_lt578i1ly35g-3>li:before {
        content: "-  "
    }

    .lst-kix_lt578i1ly35g-7>li:before {
        content: "-  "
    }

    ul.lst-kix_41hc7a3xqlgz-1 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-0 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-5.start {
        counter-reset: lst-ctn-kix_muss065vu37-5 0
    }

    ul.lst-kix_41hc7a3xqlgz-3 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-2 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-5 {
        list-style-type: none
    }

    .lst-kix_41hc7a3xqlgz-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_41hc7a3xqlgz-1>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_41hc7a3xqlgz-4 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-7 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-6 {
        list-style-type: none
    }

    ul.lst-kix_41hc7a3xqlgz-8 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-1 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-0 {
        list-style-type: none
    }

    .lst-kix_41hc7a3xqlgz-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_41hc7a3xqlgz-5>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_2hpuy1bprq1-3 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-2 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-5 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-5.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-5 0
    }

    ul.lst-kix_2hpuy1bprq1-4 {
        list-style-type: none
    }

    .lst-kix_41hc7a3xqlgz-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_41hc7a3xqlgz-6>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_2hpuy1bprq1-7 {
        list-style-type: none
    }

    ul.lst-kix_2hpuy1bprq1-6 {
        list-style-type: none
    }

    .lst-kix_lt578i1ly35g-1>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-5>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-5
    }

    .lst-kix_s3183918wdsy-8>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-8
    }

    .lst-kix_lt578i1ly35g-0>li:before {
        content: "-  "
    }

    .lst-kix_lt578i1ly35g-2>li:before {
        content: "-  "
    }

    .lst-kix_41hc7a3xqlgz-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_7mmhsfv5wlqq-1>li:before {
        content: "-  "
    }

    .lst-kix_7mmhsfv5wlqq-7>li:before {
        content: "-  "
    }

    .lst-kix_7mmhsfv5wlqq-5>li:before {
        content: "-  "
    }

    ul.lst-kix_mbq35qj9hsqb-6 {
        list-style-type: none
    }

    .lst-kix_7mmhsfv5wlqq-3>li:before {
        content: "-  "
    }

    ul.lst-kix_mbq35qj9hsqb-5 {
        list-style-type: none
    }

    .lst-kix_lt578i1ly35g-8>li:before {
        content: "-  "
    }

    ul.lst-kix_mbq35qj9hsqb-4 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-3 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-8 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-7 {
        list-style-type: none
    }

    ul.lst-kix_uf07loqdno8m-8 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-4>li {
        counter-increment: lst-ctn-kix_muss065vu37-4
    }

    ul.lst-kix_uf07loqdno8m-7 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-7.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-7 0
    }

    ul.lst-kix_uf07loqdno8m-6 {
        list-style-type: none
    }

    ul.lst-kix_uf07loqdno8m-5 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-2 {
        list-style-type: none
    }

    ul.lst-kix_mbq35qj9hsqb-1 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-3.start {
        counter-reset: lst-ctn-kix_muss065vu37-3 0
    }

    ul.lst-kix_mbq35qj9hsqb-0 {
        list-style-type: none
    }

    ul.lst-kix_uf07loqdno8m-0 {
        list-style-type: none
    }

    ul.lst-kix_uf07loqdno8m-4 {
        list-style-type: none
    }

    .lst-kix_bzf39rp48c5-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_uf07loqdno8m-3 {
        list-style-type: none
    }

    ul.lst-kix_uf07loqdno8m-2 {
        list-style-type: none
    }

    .lst-kix_68albu9x6lhe-0>li:before {
        content: "-  "
    }

    ul.lst-kix_uf07loqdno8m-1 {
        list-style-type: none
    }

    .lst-kix_bzf39rp48c5-1>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_7mmhsfv5wlqq-4 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-3 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-2 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-1 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-8 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-7 {
        list-style-type: none
    }

    .lst-kix_68albu9x6lhe-2>li:before {
        content: "-  "
    }

    .lst-kix_68albu9x6lhe-6>li:before {
        content: "-  "
    }

    ul.lst-kix_7mmhsfv5wlqq-6 {
        list-style-type: none
    }

    ul.lst-kix_7mmhsfv5wlqq-5 {
        list-style-type: none
    }

    .lst-kix_bzf39rp48c5-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_bzf39rp48c5-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_7mmhsfv5wlqq-0 {
        list-style-type: none
    }

    .lst-kix_68albu9x6lhe-4>li:before {
        content: "-  "
    }

    ol.lst-kix_muss065vu37-0.start {
        counter-reset: lst-ctn-kix_muss065vu37-0 0
    }

    .lst-kix_up8f87x9hiuk-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_up8f87x9hiuk-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_up8f87x9hiuk-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_s3183918wdsy-4>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-4
    }

    .lst-kix_ca89skfh28u5-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_up8f87x9hiuk-0>li:before {
        content: "\0025cf  "
    }

    ol.lst-kix_s3183918wdsy-8 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-6 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-7 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-4 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-5 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-2 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-3 {
        list-style-type: none
    }

    .lst-kix_up8f87x9hiuk-2>li:before {
        content: "\0025a0  "
    }

    ol.lst-kix_s3183918wdsy-0 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-1 {
        list-style-type: none
    }

    .lst-kix_fg2trobidd02-8>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-8>li:before {
        content: "-  "
    }

    .lst-kix_mbq35qj9hsqb-6>li:before {
        content: "-  "
    }

    .lst-kix_muss065vu37-5>li {
        counter-increment: lst-ctn-kix_muss065vu37-5
    }

    .lst-kix_nj0r7j4h9jqu-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_kevuw7nat4u0-1 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-0 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-0 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-8>li:before {
        content: "-  "
    }

    .lst-kix_nj0r7j4h9jqu-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_nj0r7j4h9jqu-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_s3183918wdsy-2>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-2
    }

    .lst-kix_s3183918wdsy-1>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-1, lower-roman) ") "
    }

    .lst-kix_nj0r7j4h9jqu-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_k90m6otahfkd-6 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-2>li:before {
        content: "-  "
    }

    .lst-kix_csnx2t6mi4dz-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_k90m6otahfkd-5 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-0 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-8 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-8 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-7 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-7 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-6 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-0>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-0, lower-latin) ") "
    }

    ul.lst-kix_k90m6otahfkd-2 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-5 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-1>li:before {
        content: "-  "
    }

    .lst-kix_csnx2t6mi4dz-2>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_k90m6otahfkd-1 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-4 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-4 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-3 {
        list-style-type: none
    }

    ul.lst-kix_k90m6otahfkd-3 {
        list-style-type: none
    }

    ul.lst-kix_kevuw7nat4u0-2 {
        list-style-type: none
    }

    .lst-kix_76u0k7lf7tbm-4>li:before {
        content: "-  "
    }

    .lst-kix_mfv57qacdb2q-0>li:before {
        content: "-  "
    }

    .lst-kix_csnx2t6mi4dz-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_76u0k7lf7tbm-5>li:before {
        content: "-  "
    }

    ol.lst-kix_muss065vu37-7.start {
        counter-reset: lst-ctn-kix_muss065vu37-7 0
    }

    .lst-kix_mfv57qacdb2q-1>li:before {
        content: "-  "
    }

    .lst-kix_76u0k7lf7tbm-0>li:before {
        content: "-  "
    }

    .lst-kix_mfv57qacdb2q-4>li:before {
        content: "-  "
    }

    .lst-kix_76u0k7lf7tbm-1>li:before {
        content: "-  "
    }

    .lst-kix_csnx2t6mi4dz-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_mfv57qacdb2q-8>li:before {
        content: "-  "
    }

    .lst-kix_fg2trobidd02-4>li:before {
        content: "-  "
    }

    .lst-kix_mfv57qacdb2q-5>li:before {
        content: "-  "
    }

    .lst-kix_fg2trobidd02-3>li:before {
        content: "-  "
    }

    .lst-kix_fg2trobidd02-0>li:before {
        content: "-  "
    }

    ul.lst-kix_76u0k7lf7tbm-1 {
        list-style-type: none
    }

    .lst-kix_o3r0171bkekx-1>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_68albu9x6lhe-7 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-2 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-8 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-3 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-4 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-5 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-6 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-7 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-8 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-5>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_fg2trobidd02-7 {
        list-style-type: none
    }

    .lst-kix_68albu9x6lhe-7>li:before {
        content: "-  "
    }

    ul.lst-kix_fg2trobidd02-6 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-0 {
        list-style-type: none
    }

    ul.lst-kix_fg2trobidd02-5 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-1 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-6.start {
        counter-reset: lst-ctn-kix_muss065vu37-6 0
    }

    .lst-kix_o3r0171bkekx-5>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_fg2trobidd02-4 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-2 {
        list-style-type: none
    }

    ul.lst-kix_fg2trobidd02-3 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-3 {
        list-style-type: none
    }

    ul.lst-kix_fg2trobidd02-2 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-4 {
        list-style-type: none
    }

    .lst-kix_o3r0171bkekx-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_jwbte93xw3td-6>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_fg2trobidd02-1 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-5 {
        list-style-type: none
    }

    ul.lst-kix_76u0k7lf7tbm-0 {
        list-style-type: none
    }

    ul.lst-kix_fg2trobidd02-0 {
        list-style-type: none
    }

    ul.lst-kix_68albu9x6lhe-6 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_8a59cz8kf7xm-5>li:before {
        content: "-  "
    }

    ul.lst-kix_fg2trobidd02-8 {
        list-style-type: none
    }

    .lst-kix_8a59cz8kf7xm-6>li:before {
        content: "-  "
    }

    .lst-kix_o3r0171bkekx-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_jwbte93xw3td-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_uf07loqdno8m-6>li:before {
        content: "-  "
    }

    ul.lst-kix_pw561kwiw4m0-5 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-6 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-7 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-8 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-0 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-1 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-2 {
        list-style-type: none
    }

    .lst-kix_uf07loqdno8m-5>li:before {
        content: "-  "
    }

    ul.lst-kix_pw561kwiw4m0-3 {
        list-style-type: none
    }

    ul.lst-kix_pw561kwiw4m0-4 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-7 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-8 {
        list-style-type: none
    }

    .lst-kix_8a59cz8kf7xm-2>li:before {
        content: "-  "
    }

    ul.lst-kix_up8f87x9hiuk-5 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-6 {
        list-style-type: none
    }

    .lst-kix_8a59cz8kf7xm-1>li:before {
        content: "-  "
    }

    ul.lst-kix_up8f87x9hiuk-3 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-4 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-1 {
        list-style-type: none
    }

    ul.lst-kix_up8f87x9hiuk-2 {
        list-style-type: none
    }

    .lst-kix_76u0k7lf7tbm-8>li:before {
        content: "-  "
    }

    .lst-kix_uf07loqdno8m-2>li:before {
        content: "-  "
    }

    .lst-kix_uf07loqdno8m-1>li:before {
        content: "-  "
    }

    .lst-kix_o3r0171bkekx-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_7mmhsfv5wlqq-2>li:before {
        content: "-  "
    }

    .lst-kix_7x021lqey7sq-8>li:before {
        content: "-  "
    }

    ul.lst-kix_csnx2t6mi4dz-1 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-2 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-3 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-4 {
        list-style-type: none
    }

    .lst-kix_7mmhsfv5wlqq-6>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-7>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-7
    }

    .lst-kix_7x021lqey7sq-0>li:before {
        content: "-  "
    }

    ul.lst-kix_csnx2t6mi4dz-0 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-5 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-6 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-7 {
        list-style-type: none
    }

    ul.lst-kix_csnx2t6mi4dz-8 {
        list-style-type: none
    }

    .lst-kix_yp1d32cd33ka-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_bzf39rp48c5-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_68albu9x6lhe-3>li:before {
        content: "-  "
    }

    .lst-kix_bzf39rp48c5-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_srn8alsb0dhk-4>li:before {
        content: "-  "
    }

    .lst-kix_srn8alsb0dhk-0>li:before {
        content: "-  "
    }

    .lst-kix_up8f87x9hiuk-5>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_nj0r7j4h9jqu-8 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-7 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-8>li {
        counter-increment: lst-ctn-kix_muss065vu37-8
    }

    .lst-kix_w9ka78va5rsi-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_ca89skfh28u5-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_upn6eul5dnav-8>li:before {
        content: "-  "
    }

    .lst-kix_up8f87x9hiuk-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_srn8alsb0dhk-8>li:before {
        content: "-  "
    }

    .lst-kix_w9ka78va5rsi-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_s3183918wdsy-0>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-0
    }

    .lst-kix_fg2trobidd02-7>li:before {
        content: "-  "
    }

    .lst-kix_un44sjh7oaby-6>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-8>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-8, decimal) ". "
    }

    .lst-kix_muss065vu37-7>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-7, lower-latin) ". "
    }

    .lst-kix_mbq35qj9hsqb-7>li:before {
        content: "-  "
    }

    .lst-kix_un44sjh7oaby-2>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-4>li:before {
        content: "("counter(lst-ctn-kix_s3183918wdsy-4, lower-roman) ") "
    }

    ol.lst-kix_muss065vu37-8.start {
        counter-reset: lst-ctn-kix_muss065vu37-8 0
    }

    .lst-kix_7x021lqey7sq-4>li:before {
        content: "-  "
    }

    ul.lst-kix_nj0r7j4h9jqu-4 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-3 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-6 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-5 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-0 {
        list-style-type: none
    }

    .lst-kix_2hpuy1bprq1-5>li:before {
        content: "-  "
    }

    ul.lst-kix_nj0r7j4h9jqu-2 {
        list-style-type: none
    }

    ul.lst-kix_nj0r7j4h9jqu-1 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-3>li:before {
        content: "("counter(lst-ctn-kix_muss065vu37-3, decimal) ") "
    }

    .lst-kix_k90m6otahfkd-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-8>li:before {
        content: "\0025a0  "
    }

    ol.lst-kix_muss065vu37-4.start {
        counter-reset: lst-ctn-kix_muss065vu37-4 0
    }

    .lst-kix_pw561kwiw4m0-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_k90m6otahfkd-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_9wijzkveb989-1>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_pw561kwiw4m0-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_k90m6otahfkd-4>li:before {
        content: "\0025cb  "
    }

    ol.lst-kix_s3183918wdsy-6.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-6 0
    }

    .lst-kix_pw561kwiw4m0-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_muss065vu37-0>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-0, decimal) ") "
    }

    .lst-kix_gp1ibqp1zuuw-2>li:before {
        content: "-  "
    }

    .lst-kix_9yq2uhfsggzt-4>li:before {
        content: "-  "
    }

    .lst-kix_9wijzkveb989-0>li:before {
        content: "-  "
    }

    .lst-kix_9yq2uhfsggzt-3>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_gp1ibqp1zuuw-3>li:before {
        content: "-  "
    }

    ul.lst-kix_9yq2uhfsggzt-5 {
        list-style-type: none
    }

    .lst-kix_9wijzkveb989-6>li:before {
        content: "-  "
    }

    ul.lst-kix_srn8alsb0dhk-5 {
        list-style-type: none
    }

    ul.lst-kix_9yq2uhfsggzt-4 {
        list-style-type: none
    }

    .lst-kix_k90m6otahfkd-0>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_srn8alsb0dhk-6 {
        list-style-type: none
    }

    ul.lst-kix_9yq2uhfsggzt-3 {
        list-style-type: none
    }

    ul.lst-kix_srn8alsb0dhk-3 {
        list-style-type: none
    }

    ul.lst-kix_9yq2uhfsggzt-2 {
        list-style-type: none
    }

    .lst-kix_pw561kwiw4m0-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_srn8alsb0dhk-4 {
        list-style-type: none
    }

    .lst-kix_gp1ibqp1zuuw-4>li:before {
        content: "-  "
    }

    .lst-kix_gp1ibqp1zuuw-6>li:before {
        content: "-  "
    }

    ul.lst-kix_9yq2uhfsggzt-1 {
        list-style-type: none
    }

    ul.lst-kix_srn8alsb0dhk-1 {
        list-style-type: none
    }

    ul.lst-kix_9yq2uhfsggzt-0 {
        list-style-type: none
    }

    .lst-kix_k90m6otahfkd-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_k90m6otahfkd-2>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_srn8alsb0dhk-2 {
        list-style-type: none
    }

    .lst-kix_9yq2uhfsggzt-5>li:before {
        content: "-  "
    }

    .lst-kix_9wijzkveb989-5>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_srn8alsb0dhk-0 {
        list-style-type: none
    }

    .lst-kix_gp1ibqp1zuuw-5>li:before {
        content: "-  "
    }

    .lst-kix_9yq2uhfsggzt-6>li:before {
        content: "-  "
    }

    .lst-kix_9wijzkveb989-2>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_gp1ibqp1zuuw-8>li:before {
        content: "-  "
    }

    .lst-kix_9yq2uhfsggzt-8>li:before {
        content: "-  "
    }

    .lst-kix_9wijzkveb989-4>li:before {
        content: "-  "
    }

    .lst-kix_9yq2uhfsggzt-7>li:before {
        content: "-  "
    }

    .lst-kix_9wijzkveb989-3>li:before {
        content: "-  "
    }

    .lst-kix_pw561kwiw4m0-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_gp1ibqp1zuuw-7>li:before {
        content: "-  "
    }

    ul.lst-kix_un44sjh7oaby-1 {
        list-style-type: none
    }

    ul.lst-kix_un44sjh7oaby-2 {
        list-style-type: none
    }

    ul.lst-kix_un44sjh7oaby-3 {
        list-style-type: none
    }

    ul.lst-kix_un44sjh7oaby-4 {
        list-style-type: none
    }

    ul.lst-kix_un44sjh7oaby-5 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-3>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-3
    }

    ul.lst-kix_un44sjh7oaby-6 {
        list-style-type: none
    }

    .lst-kix_upn6eul5dnav-0>li:before {
        content: "-  "
    }

    ul.lst-kix_un44sjh7oaby-7 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-0 {
        list-style-type: none
    }

    ul.lst-kix_un44sjh7oaby-8 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-8>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-5>li:before {
        content: "-  "
    }

    ul.lst-kix_9yq2uhfsggzt-8 {
        list-style-type: none
    }

    .lst-kix_upn6eul5dnav-6>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-7>li:before {
        content: "-  "
    }

    ul.lst-kix_9yq2uhfsggzt-7 {
        list-style-type: none
    }

    ul.lst-kix_un44sjh7oaby-0 {
        list-style-type: none
    }

    ul.lst-kix_9yq2uhfsggzt-6 {
        list-style-type: none
    }

    .lst-kix_9yq2uhfsggzt-2>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-4>li:before {
        content: "-  "
    }

    .lst-kix_9yq2uhfsggzt-1>li:before {
        content: "-  "
    }

    .lst-kix_gp1ibqp1zuuw-1>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-3>li:before {
        content: "-  "
    }

    .lst-kix_gp1ibqp1zuuw-0>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-1>li:before {
        content: "-  "
    }

    .lst-kix_9yq2uhfsggzt-0>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-2>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-0>li:before {
        content: "-  "
    }

    ul.lst-kix_gp1ibqp1zuuw-6 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-5 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-4 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-3 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-3>li {
        counter-increment: lst-ctn-kix_muss065vu37-3
    }

    ul.lst-kix_gp1ibqp1zuuw-8 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-7 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-4>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-2>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-6>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_gp1ibqp1zuuw-2 {
        list-style-type: none
    }

    ul.lst-kix_gp1ibqp1zuuw-1 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-1>li:before {
        content: "-  "
    }

    .lst-kix_mbzrtzx2wb9v-5>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-6>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_gp1ibqp1zuuw-0 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-2 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-1 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-4 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-3 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-6 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-5 {
        list-style-type: none
    }

    .lst-kix_mbzrtzx2wb9v-3>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_o3r0171bkekx-8 {
        list-style-type: none
    }

    ul.lst-kix_o3r0171bkekx-7 {
        list-style-type: none
    }

    ul.lst-kix_mfv57qacdb2q-8 {
        list-style-type: none
    }

    ul.lst-kix_mfv57qacdb2q-0 {
        list-style-type: none
    }

    ul.lst-kix_mfv57qacdb2q-1 {
        list-style-type: none
    }

    ul.lst-kix_mfv57qacdb2q-2 {
        list-style-type: none
    }

    ul.lst-kix_mfv57qacdb2q-3 {
        list-style-type: none
    }

    ul.lst-kix_mfv57qacdb2q-4 {
        list-style-type: none
    }

    .lst-kix_9wijzkveb989-8>li:before {
        content: "-  "
    }

    ul.lst-kix_mfv57qacdb2q-5 {
        list-style-type: none
    }

    ul.lst-kix_mfv57qacdb2q-6 {
        list-style-type: none
    }

    .lst-kix_9wijzkveb989-7>li:before {
        content: "-  "
    }

    ul.lst-kix_mfv57qacdb2q-7 {
        list-style-type: none
    }

    .lst-kix_7x021lqey7sq-1>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_yp1d32cd33ka-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_yp1d32cd33ka-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_w9ka78va5rsi-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_upn6eul5dnav-3 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-1 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-2 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-2 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-5 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-3 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-4 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-4 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-5 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-6 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-6>li {
        counter-increment: lst-ctn-kix_muss065vu37-6
    }

    ul.lst-kix_upn6eul5dnav-1 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-7 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-0 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-8 {
        list-style-type: none
    }

    .lst-kix_srn8alsb0dhk-3>li:before {
        content: "-  "
    }

    ol.lst-kix_muss065vu37-0 {
        list-style-type: none
    }

    .lst-kix_srn8alsb0dhk-1>li:before {
        content: "-  "
    }

    ul.lst-kix_mbzrtzx2wb9v-2 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-3 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-0 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-1 {
        list-style-type: none
    }

    .lst-kix_w9ka78va5rsi-1>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_mbzrtzx2wb9v-6 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-7 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-4 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-5 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-7 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-6 {
        list-style-type: none
    }

    ul.lst-kix_mbzrtzx2wb9v-8 {
        list-style-type: none
    }

    ul.lst-kix_upn6eul5dnav-8 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-2.start {
        counter-reset: lst-ctn-kix_muss065vu37-2 0
    }

    .lst-kix_srn8alsb0dhk-5>li:before {
        content: "-  "
    }

    .lst-kix_upn6eul5dnav-7>li:before {
        content: "-  "
    }

    .lst-kix_w9ka78va5rsi-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_srn8alsb0dhk-7>li:before {
        content: "-  "
    }

    .lst-kix_w9ka78va5rsi-3>li:before {
        content: "\0025cf  "
    }

    .lst-kix_un44sjh7oaby-7>li:before {
        content: "-  "
    }

    ul.lst-kix_hhnnp2o6wu1x-5 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-6 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-3 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-4 {
        list-style-type: none
    }

    .lst-kix_muss065vu37-6>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-6, decimal) ". "
    }

    .lst-kix_muss065vu37-8>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-8, lower-roman) ". "
    }

    .lst-kix_un44sjh7oaby-5>li:before {
        content: "-  "
    }

    ul.lst-kix_hhnnp2o6wu1x-7 {
        list-style-type: none
    }

    ul.lst-kix_srn8alsb0dhk-7 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-8 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-7>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-7, lower-roman) ". "
    }

    ul.lst-kix_srn8alsb0dhk-8 {
        list-style-type: none
    }

    .lst-kix_un44sjh7oaby-3>li:before {
        content: "-  "
    }

    .lst-kix_7x021lqey7sq-3>li:before {
        content: "-  "
    }

    .lst-kix_muss065vu37-2>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-2, lower-roman) ") "
    }

    .lst-kix_muss065vu37-4>li:before {
        content: "("counter(lst-ctn-kix_muss065vu37-4, lower-latin) ") "
    }

    ul.lst-kix_hhnnp2o6wu1x-1 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-2 {
        list-style-type: none
    }

    ul.lst-kix_hhnnp2o6wu1x-0 {
        list-style-type: none
    }

    .lst-kix_s3183918wdsy-5>li:before {
        content: "("counter(lst-ctn-kix_s3183918wdsy-5, decimal) ") "
    }

    .lst-kix_7x021lqey7sq-5>li:before {
        content: "-  "
    }

    .lst-kix_7x021lqey7sq-7>li:before {
        content: "-  "
    }

    .lst-kix_un44sjh7oaby-1>li:before {
        content: "-  "
    }

    ol.lst-kix_s3183918wdsy-8.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-8 0
    }

    .lst-kix_s3183918wdsy-3>li:before {
        content: "("counter(lst-ctn-kix_s3183918wdsy-3, lower-latin) ") "
    }

    .lst-kix_2hpuy1bprq1-6>li:before {
        content: "-  "
    }

    .lst-kix_2hpuy1bprq1-7>li:before {
        content: "-  "
    }

    .lst-kix_csnx2t6mi4dz-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_2hpuy1bprq1-4>li:before {
        content: "-  "
    }

    .lst-kix_muss065vu37-0>li {
        counter-increment: lst-ctn-kix_muss065vu37-0
    }

    .lst-kix_nj0r7j4h9jqu-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_2hpuy1bprq1-3>li:before {
        content: "-  "
    }

    .lst-kix_76u0k7lf7tbm-7>li:before {
        content: "-  "
    }

    .lst-kix_76u0k7lf7tbm-6>li:before {
        content: "-  "
    }

    .lst-kix_nj0r7j4h9jqu-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_csnx2t6mi4dz-1>li:before {
        content: "\0025cb  "
    }

    .lst-kix_nj0r7j4h9jqu-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_9wijzkveb989-5 {
        list-style-type: none
    }

    ol.lst-kix_muss065vu37-1.start {
        counter-reset: lst-ctn-kix_muss065vu37-1 0
    }

    .lst-kix_csnx2t6mi4dz-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_9wijzkveb989-4 {
        list-style-type: none
    }

    .lst-kix_76u0k7lf7tbm-3>li:before {
        content: "-  "
    }

    ul.lst-kix_9wijzkveb989-3 {
        list-style-type: none
    }

    ul.lst-kix_9wijzkveb989-2 {
        list-style-type: none
    }

    .lst-kix_mfv57qacdb2q-2>li:before {
        content: "-  "
    }

    .lst-kix_2hpuy1bprq1-0>li:before {
        content: "-  "
    }

    ul.lst-kix_9wijzkveb989-8 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-0 {
        list-style-type: none
    }

    ul.lst-kix_9wijzkveb989-7 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-1 {
        list-style-type: none
    }

    ul.lst-kix_9wijzkveb989-6 {
        list-style-type: none
    }

    .lst-kix_csnx2t6mi4dz-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_76u0k7lf7tbm-2>li:before {
        content: "-  "
    }

    .lst-kix_nj0r7j4h9jqu-5>li:before {
        content: "\0025a0  "
    }

    .lst-kix_uf07loqdno8m-8>li:before {
        content: "-  "
    }

    ul.lst-kix_9wijzkveb989-1 {
        list-style-type: none
    }

    .lst-kix_csnx2t6mi4dz-5>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_9wijzkveb989-0 {
        list-style-type: none
    }

    .lst-kix_mfv57qacdb2q-3>li:before {
        content: "-  "
    }

    .lst-kix_nj0r7j4h9jqu-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_fg2trobidd02-6>li:before {
        content: "-  "
    }

    .lst-kix_mfv57qacdb2q-6>li:before {
        content: "-  "
    }

    .lst-kix_fg2trobidd02-5>li:before {
        content: "-  "
    }

    .lst-kix_fg2trobidd02-2>li:before {
        content: "-  "
    }

    .lst-kix_mfv57qacdb2q-7>li:before {
        content: "-  "
    }

    .lst-kix_fg2trobidd02-1>li:before {
        content: "-  "
    }

    ol.lst-kix_s3183918wdsy-3.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-3 0
    }

    ul.lst-kix_yp1d32cd33ka-0 {
        list-style-type: none
    }

    .lst-kix_o3r0171bkekx-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_7x021lqey7sq-1 {
        list-style-type: none
    }

    ul.lst-kix_7x021lqey7sq-2 {
        list-style-type: none
    }

    .lst-kix_o3r0171bkekx-2>li:before {
        content: "\0025a0  "
    }

    .lst-kix_jwbte93xw3td-8>li:before {
        content: "\0025a0  "
    }

    ul.lst-kix_7x021lqey7sq-0 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-6 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-1 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-0 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-7 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-2 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-4 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-3 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-5 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-4 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-5 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_yp1d32cd33ka-6 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-8 {
        list-style-type: none
    }

    ul.lst-kix_yp1d32cd33ka-7 {
        list-style-type: none
    }

    .lst-kix_68albu9x6lhe-8>li:before {
        content: "-  "
    }

    ul.lst-kix_yp1d32cd33ka-8 {
        list-style-type: none
    }

    .lst-kix_8a59cz8kf7xm-3>li:before {
        content: "-  "
    }

    ul.lst-kix_bzf39rp48c5-8 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-7 {
        list-style-type: none
    }

    .lst-kix_8a59cz8kf7xm-4>li:before {
        content: "-  "
    }

    ul.lst-kix_bzf39rp48c5-6 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-5 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-4 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-3 {
        list-style-type: none
    }

    ul.lst-kix_bzf39rp48c5-2 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_jwbte93xw3td-4>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_bzf39rp48c5-1 {
        list-style-type: none
    }

    .lst-kix_8a59cz8kf7xm-7>li:before {
        content: "-  "
    }

    ul.lst-kix_7x021lqey7sq-5 {
        list-style-type: none
    }

    ul.lst-kix_7x021lqey7sq-6 {
        list-style-type: none
    }

    .lst-kix_8a59cz8kf7xm-8>li:before {
        content: "-  "
    }

    ul.lst-kix_7x021lqey7sq-3 {
        list-style-type: none
    }

    ul.lst-kix_7x021lqey7sq-4 {
        list-style-type: none
    }

    .lst-kix_jwbte93xw3td-3>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_7x021lqey7sq-7 {
        list-style-type: none
    }

    ul.lst-kix_7x021lqey7sq-8 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-4.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-4 0
    }

    .lst-kix_muss065vu37-7>li {
        counter-increment: lst-ctn-kix_muss065vu37-7
    }

    .lst-kix_uf07loqdno8m-3>li:before {
        content: "-  "
    }

    .lst-kix_uf07loqdno8m-7>li:before {
        content: "-  "
    }

    ul.lst-kix_ca89skfh28u5-2 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-3 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-4 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-5 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-6 {
        list-style-type: none
    }

    .lst-kix_uf07loqdno8m-4>li:before {
        content: "-  "
    }

    ul.lst-kix_ca89skfh28u5-7 {
        list-style-type: none
    }

    ul.lst-kix_ca89skfh28u5-8 {
        list-style-type: none
    }

    .lst-kix_7mmhsfv5wlqq-8>li:before {
        content: "-  "
    }

    .lst-kix_o3r0171bkekx-7>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_8a59cz8kf7xm-2 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-3 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-0 {
        list-style-type: none
    }

    ul.lst-kix_8a59cz8kf7xm-1 {
        list-style-type: none
    }

    .lst-kix_o3r0171bkekx-6>li:before {
        content: "\0025cf  "
    }

    .lst-kix_8a59cz8kf7xm-0>li:before {
        content: "-  "
    }

    .lst-kix_uf07loqdno8m-0>li:before {
        content: "-  "
    }

    .lst-kix_7mmhsfv5wlqq-0>li:before {
        content: "-  "
    }

    .lst-kix_7mmhsfv5wlqq-4>li:before {
        content: "-  "
    }

    .lst-kix_bzf39rp48c5-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_s3183918wdsy-6>li {
        counter-increment: lst-ctn-kix_s3183918wdsy-6
    }

    .lst-kix_w9ka78va5rsi-8>li:before {
        content: "\0025a0  "
    }

    .lst-kix_68albu9x6lhe-1>li:before {
        content: "-  "
    }

    .lst-kix_yp1d32cd33ka-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_bzf39rp48c5-0>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_w9ka78va5rsi-1 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-0 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-3 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-2 {
        list-style-type: none
    }

    ul.lst-kix_w9ka78va5rsi-5 {
        list-style-type: none
    }

    .lst-kix_bzf39rp48c5-4>li:before {
        content: "\0025cb  "
    }

    ul.lst-kix_w9ka78va5rsi-4 {
        list-style-type: none
    }

    .lst-kix_srn8alsb0dhk-2>li:before {
        content: "-  "
    }

    ul.lst-kix_w9ka78va5rsi-7 {
        list-style-type: none
    }

    .lst-kix_68albu9x6lhe-5>li:before {
        content: "-  "
    }

    ul.lst-kix_w9ka78va5rsi-6 {
        list-style-type: none
    }

    .lst-kix_yp1d32cd33ka-0>li:before {
        content: "\0025cf  "
    }

    ul.lst-kix_w9ka78va5rsi-8 {
        list-style-type: none
    }

    ol.lst-kix_s3183918wdsy-1.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-1 0
    }

    .lst-kix_w9ka78va5rsi-0>li:before {
        content: "\0025cf  "
    }

    .lst-kix_up8f87x9hiuk-7>li:before {
        content: "\0025cb  "
    }

    .lst-kix_w9ka78va5rsi-4>li:before {
        content: "\0025cb  "
    }

    .lst-kix_srn8alsb0dhk-6>li:before {
        content: "-  "
    }

    .lst-kix_un44sjh7oaby-8>li:before {
        content: "-  "
    }

    .lst-kix_up8f87x9hiuk-3>li:before {
        content: "\0025cf  "
    }

    ol.lst-kix_s3183918wdsy-2.start {
        counter-reset: lst-ctn-kix_s3183918wdsy-2 0
    }

    .lst-kix_7x021lqey7sq-2>li:before {
        content: "-  "
    }

    .lst-kix_un44sjh7oaby-4>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-6>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-6, lower-latin) ". "
    }

    .lst-kix_muss065vu37-2>li {
        counter-increment: lst-ctn-kix_muss065vu37-2
    }

    .lst-kix_muss065vu37-1>li:before {
        content: ""counter(lst-ctn-kix_muss065vu37-1, lower-latin) ") "
    }

    .lst-kix_muss065vu37-5>li:before {
        content: "("counter(lst-ctn-kix_muss065vu37-5, lower-roman) ") "
    }

    .lst-kix_un44sjh7oaby-0>li:before {
        content: "-  "
    }

    .lst-kix_s3183918wdsy-2>li:before {
        content: ""counter(lst-ctn-kix_s3183918wdsy-2, decimal) ") "
    }

    .lst-kix_7x021lqey7sq-6>li:before {
        content: "-  "
    }

    ol {
        margin: 0;
        padding: 0
    }

    table td,
    table th {
        padding: 0
    }

    .c21 {
        margin-left: 27pt;
        padding-top: 12pt;
        padding-bottom: 3pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c28 {
        margin-left: 27pt;
        padding-top: 12pt;
        padding-bottom: 10pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c22 {
        margin-left: 18pt;
        padding-top: 12pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c39 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 10pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: center
    }

    .c27 {
        margin-left: 72pt;
        padding-top: 0pt;
        padding-left: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c43 {
        margin-left: 27pt;
        padding-top: 15pt;
        padding-bottom: 3pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c10 {
        margin-left: 36pt;
        padding-top: 0pt;
        padding-left: 0pt;
        padding-bottom: 10pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c5 {
        margin-left: 18pt;
        padding-top: 10pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c48 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 24pt;
        line-height: 1.0;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: right
    }

    .c9 {
        margin-left: 18pt;
        padding-top: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c16 {
        margin-left: 36pt;
        padding-top: 0pt;
        padding-left: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c47 {
        margin-left: 27pt;
        padding-top: 10pt;
        padding-bottom: 3pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c17 {
        margin-left: 45pt;
        padding-top: 18pt;
        padding-bottom: 4pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c2 {
        color: #666666;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 12pt;
        font-family: "Lora";
        font-style: normal
    }

    .c4 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c1 {
        color: #000000;
        font-weight: 400;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 11pt;
        font-family: "Georgia";
        font-style: normal
    }

    .c14 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 13pt;
        font-family: "Lora";
        font-style: normal
    }

    .c23 {
        padding-top: 12pt;
        padding-bottom: 4pt;
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c0 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 24pt;
        font-family: "Lora";
        font-style: normal
    }

    .c12 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 18pt;
        font-family: "Lora";
        font-style: normal
    }

    .c32 {
        color: #000000;
        font-weight: 400;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 14pt;
        font-family: "Georgia";
        font-style: normal
    }

    .c13 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 15pt;
        font-family: "Lora";
        font-style: normal
    }

    .c18 {
        padding-top: 0pt;
        text-indent: 9pt;
        padding-bottom: 10pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c37 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        font-size: 15pt;
        font-family: "Lora";
        font-style: normal
    }

    .c44 {
        color: #000000;
        font-weight: 700;
        text-decoration: none;
        font-size: 24pt;
        font-family: "Lora";
        font-style: normal
    }

    .c40 {
        padding-top: 0pt;
        padding-bottom: 0pt;
        line-height: 1.15;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .c8 {
        color: #000000;
        text-decoration: none;
        vertical-align: baseline;
        font-size: 11pt;
        font-style: normal
    }

    .c46 {
        color: #000000;
        font-weight: 400;
        font-size: 18pt;
        font-family: "Georgia";
        font-style: normal
    }

    .c30 {
        font-size: 11pt;
        font-family: "Georgia";
        font-style: italic;
        color: #999999;
        font-weight: 400
    }

    .c20 {
        text-decoration-skip-ink: none;
        -webkit-text-decoration-skip: none;
        color: #1155cc;
        text-decoration: underline
    }

    .c29 {
        font-size: 11pt;
        font-family: "Georgia";
        color: #000000;
        font-weight: 400
    }

    .c25 {
        padding-top: 0pt;
        padding-bottom: 0pt;
        line-height: 1.0;
        text-align: left
    }

    .c35 {
        font-size: 9pt;
        font-family: "Georgia";
        color: #000000;
        font-weight: 400
    }

    .c34 {
        font-weight: 400;
        font-size: 11pt;
        font-family: "Georgia"
    }

    .c3 {
        vertical-align: sub;
        font-family: "Courier New";
        font-weight: 400
    }

    .c49 {
        background-color: #ffffff;
        max-width: 468pt;
        padding: 72pt 72pt 72pt 72pt
    }

    .c19 {
        font-weight: 400;
        font-family: "Arial"
    }

    .c6 {
        font-weight: 400;
        font-family: "Courier New"
    }

    .c15 {
        color: inherit;
        text-decoration: inherit
    }

    .c41 {
        text-decoration: none;
        vertical-align: baseline
    }

    .c11 {
        padding: 0;
        margin: 0
    }

    .c38 {
        border: 1px solid black;
        margin: 5px
    }

    .c42 {
        color: #666666;
        font-style: normal
    }

    .c45 {
        font-weight: 700;
        font-family: "Georgia"
    }

    .c36 {
        font-size: 13.5pt
    }

    .c7 {
        vertical-align: super
    }

    .c31 {
        font-style: italic
    }

    .c26 {
        height: 11pt
    }

    .c33 {
        margin-left: 36pt
    }

    .c24 {
        vertical-align: sub
    }

    .title {
        padding-top: 0pt;
        color: #000000;
        font-size: 26pt;
        padding-bottom: 3pt;
        font-family: "Georgia";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    .subtitle {
        padding-top: 0pt;
        color: #666666;
        font-size: 15pt;
        padding-bottom: 16pt;
        font-family: "Arial";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    li {
        color: #000000;
        font-size: 11pt;
        font-family: "Georgia"
    }

    p {
        margin: 0;
        color: #000000;
        font-size: 11pt;
        font-family: "Georgia"
    }

    h1 {
        padding-top: 18pt;
        color: #000000;
        font-weight: 700;
        font-size: 18pt;
        padding-bottom: 4pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h2 {
        padding-top: 12pt;
        color: #000000;
        font-weight: 700;
        font-size: 15pt;
        padding-bottom: 3pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h3 {
        padding-top: 12pt;
        color: #000000;
        font-weight: 700;
        font-size: 13pt;
        padding-bottom: 0pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h4 {
        padding-top: 0pt;
        color: #666666;
        font-weight: 700;
        font-size: 12pt;
        padding-bottom: 0pt;
        font-family: "Lora";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h5 {
        padding-top: 12pt;
        color: #666666;
        font-size: 11pt;
        padding-bottom: 4pt;
        font-family: "Georgia";
        line-height: 1.15;
        page-break-after: avoid;
        orphans: 2;
        widows: 2;
        text-align: left
    }

    h6 {
        padding-top: 12pt;
        color: #666666;
        font-size: 11pt;
        padding-bottom: 4pt;
        font-family: "Georgia";
        line-height: 1.15;
        page-break-after: avoid;
        font-style: italic;
        orphans: 2;
        widows: 2;
        text-align: left
    }
    </style>
</head>

<body class="c49">

    <p>Updated: 6:23pm</p>
    <p>Note: This is not an official study guide. This does not encompass every topic.</p>
    <p class="c39 title" id="h.af2d0hbx4i0d"><span class="c44">Computer Vision Midterm Study Guide</span></p>
    <p class="c48 subtitle"><span class="c30">Contributors: Ibrahim Tigrek, Ahmed Gamal</span></p>
    <h1 class="c17" id="h.abbw2mu8xyt2"><span class="c12">Important Topics</span></h1>
    <h2 class="c21" id="h.z7hkcegwwwg5"><span>Cross-Validation</span><span class="c20 c7"><a class="c15" href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttp://cs231n.github.io/classification/%26sa%3DD%26ust%3D1574278799830000&amp;sa=D&amp;ust=1574310063860000">2.2</a></span></h2>
    <h4 class="c9" id="h.h8q0hqpuyym"><span class="c2">Purpose</span></h4>
    <p class="c4"><span>The purpose of cross validation is t</span><span>o determine the optimum values of the hyperparameters, which are </span><span class="c1">the parameters that are set for the algorithm.</span></p>
    <p class="c4"><span>k-</span><span>fold cross-validation is performed by dividing the training set into k sets, each one called a fold. Let&rsquo;s take k = 5, which is what is usually used. First, we train a model with a certain set of hyperparameters on the first 4 folds, and validate it (i.e. test it) on the 5th fold. Then we do the same, but this time the </span><span class="c31">validation set</span><span class="c1">&nbsp;is the 4th fold. Then again with the 3rd fold, and so on for all 5 possible combinations. For each of these iterations, we get a performance measure. We average these to get the final performance measure of the model with this specific set of hyperparameters.</span></p>
    <p class="c4"><span class="c1">We do all of this again for another model, that has a different set of hyperparameters. And again for another model, and so on. Once we are satisfied with all the combinations of hyperparameters that we have validated, we choose the model that gave us the best overall performance measure. Then, and only then, do we use the test data, to test our final model.</span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <h2 class="c21" id="h.r9s32jnwg1t2"><span>Regularization</span><span class="c34 c7">2.7</span></h2>
    <p class="c4"><span>Regularization is a penalty term added to the loss function to keep the </span><span>weights</span><span class="c1">&nbsp;low. The strength of regularization depends on the hyperparameter &lambda;. Regularization makes the model simpler, and spreads out the weights.When building neural networks, it is recommended to start with as many neurons as the computer can handle, and apply regularization.</span></p>
    <p class="c4"><span class="c1">The loss function with regularization looks like</span></p>
    <p class="c4"><img src="images/image1.png"></p>
    <p class="c4"><span>where </span><img src="images/image2.png"><span class="c1">&nbsp;is the regularization loss.</span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <h4 class="c9" id="h.nlfknrw5d073"><span class="c2">L1 regularization</span></h4>
    <p class="c4"><img src="images/image3.png"></p>
    <p class="c4"><span class="c1">Also called Lasso regression. Lasso regression usually reduces useless features to zero.</span></p>
    <p class="c40"><span class="c1">&nbsp; &nbsp; L1 used for feature </span></p>
    <h4 class="c9" id="h.bygdaau62vgc"><span class="c2">L2 regularization</span></h4>
    <ul class="c11 lst-kix_7x021lqey7sq-0 start">
        <li class="c16"><span class="c1">The most common way of regularization.</span></li>
    </ul>
    <ul class="c11 lst-kix_9wijzkveb989-0 start">
        <li class="c16"><span class="c1">R(W) summing up all the squared element of W </span></li>
    </ul>
    <p class="c4"><img src="images/image4.png"></p>
    <p class="c4"><span>L2 regularization is a</span><span class="c1">lso called Ridge regression. This function is differentiable.</span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <ul class="c11 lst-kix_8a59cz8kf7xm-0 start">
        <li class="c16"><span class="c1">Penalizing weight improve generalization suppose we have two weight vectors W1=[1,0,0,0] and W2=[0.25,0.25,0.25,0.25] both have the same output, however according to L2 norm &nbsp;the second vector is more preferable as it will achieve lower regularization loss &nbsp;the penalty of (W1=1),(W2=0.25)</span></li>
        <li class="c16"><span class="c1">This function improves the image classification and lead to less overfitting. </span></li>
        <li class="c16"><span class="c1">Due to this regularization penalty we can&rsquo;t achieve the 0 loss unless the W=0</span></li>
    </ul>
    <p class="c4 c26"><span class="c1"></span></p>
    <h4 class="c9" id="h.7h2s7e9uoife"><span class="c2">Elastic net regularization</span></h4>
    <p class="c4"><span class="c1">Is a combination of lasso and ridge regression. A hyperparameter (r) determines how much of lasso and ridge are used. </span></p>
    <p class="c4"><img></p>
    <h4 class="c9" id="h.hv0e50arnb62"><span class="c2">Max norm constraints</span></h4>
    <p class="c4"><span class="c1">Ensures that the norm of all of the weights is less than a specified bound. This is to prevent the neurons from becoming saturated.</span></p>
    <h4 class="c9" id="h.r1tdi9pfjerc"><span class="c2">Dropout regularization</span></h4>
    <p class="c4"><span class="c1">Starting with a fully-connected neural network, some neurons are killed off randomly based on a predefined probability. The &ldquo;killing&rdquo; of the neurons is done by cutting off all of the input to that neuron.</span></p>
    <p class="c4"><span class="c1">Dropout regularization is used to weaken the strength of the network, thus making it harder for it to memorize the training data.</span></p>
    <h4 class="c9" id="h.qvmzvt7fvtea"><span class="c2">Bias regularization</span></h4>
    <p class="c4"><span class="c1">Bias does not require regularization. However, choosing to regularize the bias values will most probably not lead to worse performance.</span></p>
    <h2 class="c21" id="h.441g8zed6ppz"><span class="c13">Gradient Descent</span></h2>
    <p class="c4"><span class="c1">For every weight, the partial derivative of the loss function with respect to that weight is determined. Then, that weight is decreased by the product of the step size and the gradient (the partial derivative).</span></p>
    <p class="c4"><img src="images/image5.png"></p>
    <h4 class="c9" id="h.obubqvsecfde"><span class="c2">Mini-batch gradient descent</span></h4>
    <p class="c4"><span class="c1">A small group of data points (e.g. 128) are used to determine the gradient.</span></p>
    <h4 class="c9" id="h.dy6v9bqvexpv"><span class="c2">Stochastic gradient descent</span></h4>
    <p class="c4"><span class="c1">The gradient is calculated and a step is taken for single data point. The data point in question is chosen randomly from the full dataset.</span></p>
    <h4 class="c9" id="h.io8bkvjhlg0f"><span class="c2">Numerical gradient</span></h4>
    <p class="c4"><span class="c1">Finding the gradient by taking two points that are close to each other and dividing the difference in y-values by the difference in their x-values. The numerical gradient can be computed for each case. It can be computed even if the original function is unknown analytically. </span></p>
    <p class="c4"><span class="c1">If the distance between the x-values of the two points is h, and the smaller of the two is x, the numerical gradient can be computed as follows.</span></p>
    <p class="c4"><img src="images/image6.png"></p>
    <h4 class="c9" id="h.yrr4q5aupcr"><span class="c2">Analytic gradient</span></h4>
    <p class="c4"><span class="c1">The formula for the exact gradient.</span></p>
    <h2 class="c21" id="h.8e95tcb8x7px"><span>Back-propagation</span><span class="c20 c7"><a class="c15" href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttp://cs231n.github.io/optimization-2/%26sa%3DD%26ust%3D1574278799831000&amp;sa=D&amp;ust=1574310063880000">2.5</a></span><span class="c7">, </span><span class="c20 c7"><a class="c15" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dd14TUNcbn1k%26t%3D1098s&amp;sa=D&amp;ust=1574310063881000">3.1</a></span></h2>
    <h4 class="c9" id="h.a642lt558l5g"><span class="c2">The Algorithm</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 187.00px; height: 146.16px;"><img alt="" src="images/image18.png" style="width: 218.70px; height: 164.43px; margin-left: -31.70px; margin-top: -9.14px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h4>
    <p class="c4"><span>Each node is examined independently, where only the input values, the output value, and the gradient propagating back to this node are necessary. Let&rsquo;s call our node N, and the two inputs x and y. Let&rsquo;s call the function at this node f, where f produces the output of this node from x and y, i.e. the output is f(x, y). Finally, let&rsquo;s call the gradient that has propagated back to N from the next node, d. It is our job to compute the gradients d</span><span class="c24">x</span><span>&nbsp;and d</span><span class="c24">y</span><span>, which are the gradients that N will propagate back to the nodes before it, where d</span><span class="c24">x</span><span>&nbsp;will go back along the path that brought x to N, and d</span><span class="c24">y</span><span class="c1">&nbsp;similarly for y.</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">x</span><span class="c8 c6">&nbsp;= d * f&rsquo;(x)</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">y</span><span class="c8 c6">&nbsp;= d * f&rsquo;(y)</span></p>
    <p class="c4"><span>where </span><span class="c6">f&rsquo; </span><span>is the partial derivative of f with respect to the argument. If, when computing </span><span class="c6">f&rsquo;(x)</span><span class="c1">, the function contains the variable y, then the value of the input in that specific case is used.</span></p>
    <h4 class="c9" id="h.a9thrik9xptw"><span class="c2">Patterns</span></h4>
    <p class="c4"><span class="c1">Some gates (nodes) have simple interpretations:</span></p>
    <h5 class="c23" id="h.99dlv3tzqom9"><span class="c34 c41 c42">Add gate</span></h5>
    <p class="c4"><span class="c1">f(x, y) = x + y</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">x</span><span class="c8 c6">&nbsp;= d</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">y</span><span class="c8 c6">&nbsp;= d</span></p>
    <h5 class="c23" id="h.2etqda1u6txk"><span class="c34 c41 c42">Max gate</span></h5>
    <p class="c4"><span class="c1">f(x, y) = max(x, y), assuming x &gt; y,</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">x</span><span class="c6 c8">&nbsp;= d</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">y</span><span class="c8 c6">&nbsp;= 0</span></p>
    <h5 class="c23" id="h.2ysxt030sj3t"><span class="c34 c41 c42">Multiply gate</span></h5>
    <p class="c4"><span class="c1">f(x, y) = x * y</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">x</span><span class="c8 c6">&nbsp;= d * y</span></p>
    <p class="c4"><span class="c6">d</span><span class="c3">y</span><span class="c6">&nbsp;= d * x</span></p>
    <h2 class="c21" id="h.460fkihq20vk"><span>Linear Classification</span><span class="c20 c7 c34"><a class="c15" href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttp://cs231n.github.io/classification/%26sa%3DD%26ust%3D1574278799830000&amp;sa=D&amp;ust=1574310063888000">2.2</a></span></h2>
    <p class="c4"><span class="c1">There are no hidden layers in the neural network.</span></p>
    <p class="c4"><span class="c1">- More powerful than KNN and it doesn&#39;t memorize the data it is less expensive in computation as it uses only one image calculation instead of comparing it with all the training images. </span></p>
    <p class="c4"><span class="c1">- We will need the score function to map row data to class score and a loss function to calculate the difference between the predicted score and the truth labels &nbsp;.</span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <p class="c4"><span class="c1">- the score function :</span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <p class="c4 c33"><span class="c1">a) xi&isin;RD &nbsp;xi images with labels yi....N</span></p>
    <p class="c4 c33"><span class="c1">b) yi&isin;1&hellip;K &nbsp; labels are element of range 1...K</span></p>
    <p class="c4 c33"><span class="c1">c) if we have N examples of dimension &nbsp;and Categories K</span></p>
    <p class="c4 c33"><span class="c1">d) &nbsp;the score function f:RD&#8614;RK</span></p>
    <p class="c4 c33"><span class="c1">example CIFAR 10 K = 10 categories</span></p>
    <p class="c4 c33"><span class="c1">N = 50K &nbsp;and D = 32*32*3 pixels</span></p>
    <p class="c4 c26 c33"><span class="c1"></span></p>
    <ul class="c11 lst-kix_2hpuy1bprq1-0 start">
        <li class="c16"><span class="c1">Linear classifier : </span></li>
    </ul>
    <ol class="c11 lst-kix_s3183918wdsy-0 start" start="1">
        <li class="c27"><span class="c1">Flatten the images xi to the vector b[K*1] </span></li>
        <li class="c27"><span class="c1">The matrix W[D*K] &nbsp;and the vector b[K*1] &nbsp;are the parameters </span></li>
        <li class="c27"><span class="c1">Then we can add the function f(xi,W,b) = Wxi + b</span></li>
        <li class="c27"><span class="c1">As W is the weight parameter and b is the bias vector </span></li>
        <li class="c27"><span>(x</span><span class="c24">i</span><span>&nbsp;,y</span><span class="c24">i</span><span class="c1">) &nbsp;are fixed but we have control over (W,b) </span></li>
        <li class="c27"><span class="c1">Every row in W is a certain classifier. </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 374.12px; height: 133.50px;"><img alt="" src="images/image17.png" style="width: 374.12px; height: 133.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li>
    </ol>
    <p class="c40 c26"><span class="c1"></span></p>
    <h4 class="c9" id="h.wirufibgya9r"><span class="c2">Bias trick</span></h4>
    <p class="c4"><span>Usually, the input vector x, to a neuron, is fed through the following formula: </span><span class="c6">y = Wx + b</span><span>, where W is a matrix; y and b are vectors. But the bias trick allows us to use only one matrix without adding a bias separately; by concatenating W with b which creates </span><span class="c6">W&rsquo;</span><span>and adding 1 to the bottom of the x vector, creating</span><span class="c6">&nbsp;x&rsquo;.</span><span>&nbsp;So, we get the same y as earlier by</span><span class="c6">&nbsp;y = W&rsquo; * x&rsquo;. </span><span class="c1">(Illustrated above)</span></p>
    <p class="c4 c26"><span class="c8 c6"></span></p>
    <h4 class="c9" id="h.9vn6elcnwkqb"><span class="c2">Softmax classifier</span></h4>
    <p class="c4"><span class="c1">(Multinomial Logistic Regression)</span></p>
    <p class="c4"><span>This classifier gives the probability of each class label based on the softmax function. (see </span><span class="c20"><a class="c15" href="#h.ng115ad76ez">softmax loss function</a></span><span class="c1">)</span></p>
    <p class="c4"><span class="c1">When the number of labels is really large, a variation of softmax, called &ldquo;hierarchical softmax&rdquo;, is used, since it is faster to evaluate.</span></p>
    <h1 class="c17" id="h.vj9f20camcvs"><span class="c12">Related Topics</span></h1>
    <h2 class="c21" id="h.xlehv8hw21ad"><span class="c13">Perceptron</span></h2>
    <p class="c18"><span>A</span><span class="c29">&nbsp;network consisting of inputs feeding into a single neuron </span><span>which has </span><span class="c29">a step function as its activation function. Single p</span><span>erceptron wasn&rsquo;t enough to solve the XOR-problem. However, creating a hidden layer with two perceptrons can solve the problem.</span></p>
    <h2 class="c21" id="h.u3l6b5nyhh14"><span class="c13">Activation functions</span></h2>
    <h4 class="c9" id="h.34edzig8hemd"><span class="c2">step function</span></h4>
    <h4 class="c9" id="h.34edzig8hemd-1"><span class="c2">sigmoid function</span></h4>
    <h4 class="c9" id="h.34edzig8hemd-2"><span class="c2">hyperbolic tangent function</span></h4>
    <h4 class="c9" id="h.75wcoj949i5w"><span class="c2">relu (rectified linear unit) function</span></h4>
    <p class="c4"><span class="c1">Most commonly used in neural networks.</span></p>
    <h2 class="c21" id="h.i98ollver278"><span class="c13">Loss functions</span></h2>
    <p class="c4"><span>Consist of two parts: the error and the regularization. (see </span><span class="c20"><a class="c15" href="#h.r9s32jnwg1t2">Regularization</a></span><span class="c1">)</span></p>
    <h4 class="c9" id="h.y0ptdaf1jgin"><span class="c2">Multiclass SVM loss</span></h4>
    <ul class="c11 lst-kix_9yq2uhfsggzt-0 start">
        <li class="c16"><span class="c1">loss calculated by taking the average differences between the right class prediction, if the right prediction is not higher than the wrong one with at least the safety margin.</span></li>
    </ul>
    <p class="c4"><span>(S</span><span class="c24">j</span><span>) is the score of </span><span>j, and the &nbsp;</span><span>S</span><span class="c24">yi</span><span>&nbsp;is the true score of label y , and </span><img src="images/image7.png"><span class="c1">&nbsp;is the sum of the incorrect classes </span></p>
    <p class="c4"><img src="images/image8.png"><span class="c1">&nbsp; &nbsp; Note: safety margin here is 1.</span></p>
    <ul class="c11 lst-kix_76u0k7lf7tbm-0 start">
        <li class="c16"><span class="c36">&Delta; = 1 </span><span>&nbsp;in the practical consideration as &nbsp;the difference between </span><span class="c36">&Delta;=1 </span><span>or 100 is meaningless as the weight can be stretch or shrink depends on </span><span class="c36 c31">&lambda;( </span><span>how much we allow the weight to grow through penalty). </span><span>&nbsp;</span></li>
    </ul>
    <ul class="c11 lst-kix_fg2trobidd02-0 start">
        <li class="c16"><span>If &nbsp;y</span><span class="c24">i </span><span class="c1">= 0 means the class was correctly labeled &nbsp;the first part of the equation will be 0 and the second part will be positive number which due to the safety margin in this case = 1, in short svm loss wants the correct labels to be higher in the score with at least the safety margin. </span></li>
    </ul>
    <h4 class="c9" id="h.g3foklfps5wm"><span class="c2">Hinge loss</span></h4>
    <p class="c26 c40"><span class="c1"></span></p>
    <p class="c4"><img src="images/image9.png"><span class="c1">&nbsp; where t=1, if 1 is the intended output. </span></p>
    <p class="c4"><span>And </span><img src="images/image10.png"><span class="c1">&nbsp;is the classifier score. </span></p>
    <p class="c4"><span>The hinge los is the threshold at zero </span><span class="c31">max</span><span>(0,&minus;),</span><span class="c36">&nbsp;</span><span>in some dataset squared hinge loss work better &nbsp;max(0,- )</span><span class="c7">2 </span><span>&nbsp;however the unsquared version is more standard. </span></p>
    <h4 class="c9" id="h.ng115ad76ez"><span class="c2">Softmax loss function</span></h4>
    <ul class="c11 lst-kix_68albu9x6lhe-0 start">
        <li class="c16"><span>We keep f(x</span><span class="c24">i</span><span>, W) = Wx</span><span class="c24">i</span><span class="c1">&nbsp;as the SVM </span></li>
        <li class="c16"><span class="c1">Interbert the unnormalized log for each class and replace the hinge loss with cross-entropy </span></li>
        <li class="c16"><span class="c1">It takes a vector of arbitrary real-valued and squashes it to a vector of values between zero and one that sum to one</span></li>
    </ul>
    <p class="c4"><img src="images/image11.png"></p>
    <p class="c4"><span>where </span><img src="images/image12.png"></p>
    <p class="c4"><span>y^</span><span class="c24">k </span><span class="c1">&nbsp;is the prediction scores of the classes k &nbsp;</span></p>
    <p class="c4"><span>Nominator e</span><span class="c7">s</span><span>k</span><span class="c7">(x)</span><span class="c24">&nbsp;</span><span class="c1">is the &nbsp;e to the power of s score of the right predication &nbsp;in K &nbsp;clases </span></p>
    <p class="c4"><span class="c1">Denominator is the submission of &nbsp;e to the power of all score predictions &nbsp;</span></p>
    <p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 302.67px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 302.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <h4 class="c9" id="h.mhz5ssbcueo5"><span class="c2">Log loss function</span></h4>
    <p class="c4"><img src="images/image13.png"></p>
    <p class="c4"><span>where </span><img src="images/image10.png"><span class="c1">&nbsp;is the output of the prediction fed through the sigmoid activation function.</span></p>
    <h4 class="c9" id="h.jsc83bjkdul7"><span class="c2">Cross entropy loss function</span></h4>
    <p class="c4"><img src="images/image14.png"></p>
    <h2 class="c21" id="h.qdngtzlobw9f"><span class="c13">Nearest neighbor classifier</span></h2>
    <p class="c4"><span>Memorizes all data and labels. Predicts the label of the closest data point. (see </span><span class="c20"><a class="c15" href="#h.qt9qbjyo8ex0">L1 and L2 distance</a></span><span class="c1">)</span></p>
    <h2 class="c21" id="h.qt9qbjyo8ex0"><span>k-nearest neighbor classifier </span><span class="c20 c7"><a class="c15" href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttp://cs231n.github.io/classification/%26sa%3DD%26ust%3D1574278799830000&amp;sa=D&amp;ust=1574310063913000">2</a></span><span class="c20 c7"><a class="c15" href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttp://cs231n.github.io/classification/%26sa%3DD%26ust%3D1574278799830000&amp;sa=D&amp;ust=1574310063914000">.2</a></span></h2>
    <p class="c4"><span class="c1">KNN summary : - in image classification we start with the training set and labels and must predict labels on test sets</span></p>
    <p class="c4"><span class="c1">- the KNN classifier predict labels based on the nearest neighbors:</span></p>
    <p class="c4"><span class="c1">- distance metrics and K are the hyper-parameters choose this in the validation set.</span></p>
    <p class="c4"><span class="c1">Two different distances</span></p>
    <ol class="c11 lst-kix_muss065vu37-0 start" start="1">
        <li class="c16"><span>Manhattan distance : </span><img src="images/image15.png"></li>
        <li class="c16"><span>Euclidean distance : </span><img src="images/image16.png"></li>
    </ol>
    <p class="c4"><span class="c1">Predicts based on classes of majority of labels of k nearest neighbors. Odd number is used for k to prevent stalemate vote.</span></p>
    <p class="c4"><span>This classifier does no work to train.</span></p>
    <h2 class="c21" id="h.ljjiaff9bjy6"><span class="c13">Approximate nearest neighbor</span></h2>
    <p class="c4"><span class="c1">Gives a neighbor that is very likely to be the nearest neighbor but doesn&rsquo;t guarantee it.</span></p>
    <h2 class="c21" id="h.o0pqsn0uu7d"><span class="c13">Viewpoints</span></h2>
    <ul class="c11 lst-kix_hhnnp2o6wu1x-0 start">
        <li class="c16"><span class="c1">algebraic</span></li>
        <li class="c16"><span class="c1">visual</span></li>
        <li class="c16"><span class="c1">geometric</span></li>
    </ul>
    <h2 class="c43" id="h.s6d5od5pkzlu"><span class="c13">Optimization</span></h2>
    <h4 class="c9" id="h.c5re9lng8m7i"><span class="c2">Strategies</span></h4>
    <p class="c4"><span>r</span><span class="c1">andom search</span></p>
    <p class="c4"><span class="c1">random local search</span></p>
    <p class="c4"><span>following the gradient (see </span><span class="c20"><a class="c15" href="#h.441g8zed6ppz">gradient descent</a></span><span class="c1">)</span></p>
    <h2 class="c21" id="h.ekdtc5tubypw"><span class="c13">Activation functions</span></h2>
    <p class="c4"><span class="c1">sigmoid</span></p>
    <p class="c4"><span class="c1">relu</span></p>
    <p class="c4"><span class="c1">hyperbolic tangent</span></p>
    <p class="c4"><span class="c1">leaky relu</span></p>
    <p class="c4"><span>maxout</span></p>
    <h2 class="c21" id="h.8x454o2fohmq"><span class="c13">Single neuron classifiers</span></h2>
    <p class="c4"><span class="c1">Binary softmax classifier</span></p>
    <p class="c4 c26"><span class="c1"></span></p>
    <p class="c18"><span class="c29">Binary SVM classifier(</span><span class="c35">Practical Considerations</span><span class="c29">)</span><span class="c7">2.3</span></p>
    <ul class="c11 lst-kix_uf07loqdno8m-0 start">
        <li class="c10"><span class="c1">Special case of SVM when we have only 2 classes</span></li>
    </ul>
    <p class="c18"><span>L</span><span class="c24">i</span><span>=C max (0,1&minus;y</span><span class="c24">i</span><span>w</span><span class="c7">T</span><span>x</span><span class="c24">i</span><span class="c1">)+R(W)</span></p>
    <ul class="c11 lst-kix_un44sjh7oaby-0 start">
        <li class="c10"><span>Where C is a hyperparameter and y</span><span class="c24">i</span><span>&nbsp;is </span><span class="c36">&isin; </span><span class="c1">{-1,1}</span></li>
        <li class="c10"><span class="c1">And C has a reciprocal relationship between limda &nbsp;C&prop;1/&lambda;</span></li>
        <li class="c10"><span>The SVM presented in this course is AVA which is more powerful than OVA and other multi classifier.</span></li>
    </ul>
    <h2 class="c47" id="h.5k3i3zsc20uw"><span>Data preprocessing</span><span class="c34 c7">2.7</span></h2>
    <p class="c4 c26"><span class="c1"></span></p>
    <p class="c4"><span class="c8 c45">Mean Subtraction</span></p>
    <p class="c4"><span class="c1">Subtracting the mean from every individual feature to centralize the data around the origin, can be done by subtracting a single value or one value for every RGB color channel.</span></p>
    <h3 class="c22" id="h.4e1m9a3n7dvu"><span class="c14">Normalization</span></h3>
    <p class="c4"><span class="c1">Make the data dimension almost in the same scale the most convenient way is to divide by the standard deviation after the data centralization.</span></p>
    <h3 class="c22" id="h.gt0ilvfz1lin"><span class="c14">PCA (principal component analysis)</span></h3>
    <p class="c4"><span class="c1">1- &nbsp;Centralize the data with mean subtraction. </span></p>
    <p class="c4"><span class="c1">2- calculate the covariance matrix which demonstrate the correlation structure.</span></p>
    <p class="c4"><span class="c1">3- &nbsp;compute the SVD (singular value decomposition) </span></p>
    <p class="c4"><span class="c1">4- calculate three columns in np array U(the eigenvector) S(the singular values) and V </span></p>
    <p class="c4"><span class="c1">5- to decorrelate the data we simply multiply the U * X(the centralized data) &nbsp;in Xrot </span></p>
    <p class="c4"><span class="c1">6- &nbsp;the covariance matrix of Xrot shows the new diagonal which returns the U vector when applying the SVD. </span></p>
    <p class="c4"><span class="c1">7- using the U vector we can reduce the dimensionality by choosing the top eigenvalues and discarding the data with no variance </span></p>
    <h3 class="c22" id="h.qgysi4ifl62l"><span class="c14">Whitening</span></h3>
    <p class="c4"><span class="c1">Continuing on the PCA step you can apply the whitening by taking the eigenbasis and divide every dimension by eigenvalue. if the input data is a multivariable gaussian, then the whitened data will be a gaussian with zero mean and identity covariance matrix</span></p>
    <p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 172.00px;"><img alt="" src="images/image19.png" style="width: 624.00px; height: 172.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
    <h2 class="c47" id="h.n8u481e84pk6"><span class="c13">Weight initialization</span></h2>
    <h4 class="c9" id="h.8yjwux8cr6b5"><span class="c2">all zero initialization</span></h4>
    <p class="c4"><span class="c1">All the weights are initialized to zero. The downside is that this will cause all of them to undergo the same parameter updates. This means there is no asymmetry among the weights, making the network struggle to learn.</span></p>
    <h4 class="c9" id="h.2c5acm7or6c7"><span class="c2">small random numbers</span></h4>
    <p class="c4"><span class="c1">The weights of the neurons are all random and unique in the beginning, so they will compute distinct updates and integrate themselves as diverse parts of the full network. A problem is that the variance grows with the number of inputs.</span></p>
    <h4 class="c9" id="h.lnyd2mdsw9h1"><span class="c2">calibrating variances</span></h4>
    <p class="c4"><span class="c1">Compensates for the increasing variance by scaling each neurons weight vector by the square root of the number of inputs to that neuron.</span></p>
    <h4 class="c9" id="h.wc2cxirs0g83"><span class="c2">sparse initialization</span></h4>
    <p class="c4"><span>Weight matrices initialized as zero, but each neuron is randomly connected to a fixed number of neurons, </span><span>not to all</span><span class="c1">&nbsp;of them.</span></p>
    <h2 class="c21" id="h.l6e9b9ing0hj"><span class="c13">Bias initialization</span></h2>
    <p class="c4"><span class="c1">Zero-bias initialization works fine.</span></p>
    <h2 class="c21" id="h.1mxrye7qj82z"><span class="c13">Batch normalization</span></h2>
    <p class="c4"><span>Normalizing the output of a </span><span>layer</span><span class="c1">&nbsp;before passing it to the next layer. This is to ensure that the neurons don&rsquo;t get saturated.</span></p>
    <h2 class="c43" id="h.dtp51kmgxf13"><span class="c13">Overfitting and Underfitting</span></h2>
    <p class="c4"><span class="c1">The desired model is the one that is neither high bias nor high variance.</span></p>
    <h4 class="c9" id="h.ezjt1trs5k1b"><span class="c2">High-bias</span></h4>
    <p class="c4"><span class="c1">A model that is too simple is considered to have high bias and low variance. It is also called under-fitting.</span></p>
    <h4 class="c9" id="h.lzb4ugqwfjyz"><span class="c2">High-variance</span></h4>
    <p class="c4"><span class="c1">A model that is too complex is considered to have high variance and low bias. It is also called over-fitting.</span></p>
    <h2 class="c21" id="h.53sil47c1hok"><span class="c13">Saturation of a neuron</span></h2>
    <p class="c4"><span class="c1">This occurs when the output of a neuron is insensitive to the input, i.e. it is the same regardless of any changes to the input. This is considered a dead, or dying, neuron. This happens when the input value has become very large or very small (negative).</span></p>
    <h2 class="c21" id="h.dt7nchdtvn2a"><span class="c13">Additional topics</span></h2>
    <p class="c4"><span class="c1">binary cross entropy</span></p>
    <p class="c4"><span class="c1">L2 regression loss function</span></p>
    <p class="c4"><span class="c1">Momentum optimization</span></p>
    <p class="c4"><span class="c1">Stratified sampling</span></p>
    <p class="c4"><span class="c1">Vanishing gradient problem</span></p>
    <p class="c4"><span class="c1">SIFT (scale-invariant feature transform)</span></p>
    <p class="c4"><span class="c1">One-shot learning</span></p>
    <h1 class="c17" id="h.7jwdpdkaxu4t"><span class="c12">Appendix</span></h1>
    <h2 class="c21" id="h.se5mth9nayk6"><span class="c13">Main resources</span></h2>
    <h3 class="c22" id="h.j5ase9f9gh05"><span class="c14">Packt textbook Ch. 1 </span></h3>
    <p class="c18"><span class="c20 c34"><a class="c15" href="https://www.google.com/url?q=https://subscription.packtpub.com/book/data/9781788830645/1/ch01lvl1sec02/computer-vision-in-the-wild&amp;sa=D&amp;ust=1574310063934000">https://subscription.packtpub.com/book/data/9781788830645/1/ch01lvl1sec02/computer-vision-in-the-wild</a></span></p>
    <h3 class="c22" id="h.d3xip9nt8msq"><span class="c14">Stanford Neural Networks</span></h3>
    <h4 class="c9" id="h.o9b4myvpyvxc"><span class="c2">Main page</span></h4>
    <p class="c4"><span class="c7">2.1</span><span>&nbsp;</span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/&amp;sa=D&amp;ust=1574310063935000">http://cs231n.github.io/</a></span></p>
    <h4 class="c9" id="h.xj8p7u56q44h"><span class="c2">Classification</span></h4>
    <p class="c4"><span class="c7">2.2</span><span>&nbsp;</span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/classification/&amp;sa=D&amp;ust=1574310063935000">http://cs231n.github.io/classification/</a></span></p>
    <h4 class="c9" id="h.cxtmt6uu70eb"><span class="c2">Linear classification</span></h4>
    <p class="c4"><span class="c7">2.3 </span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/linear-classify/&amp;sa=D&amp;ust=1574310063936000">http://cs231n.github.io/linear-classify/</a></span></p>
    <h4 class="c9" id="h.og6hu97zmjo"><span class="c2">Optimization</span></h4>
    <p class="c4"><span class="c7">2.4 </span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/optimization-1/&amp;sa=D&amp;ust=1574310063937000">http://cs231n.github.io/optimization-1/</a></span></p>
    <h4 class="c9" id="h.a0bztbttu3gy"><span class="c2">Back-propagation</span></h4>
    <p class="c4"><span class="c7">2.5 </span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/optimization-2/&amp;sa=D&amp;ust=1574310063938000">http://cs231n.github.io/optimization-2/</a></span></p>
    <h4 class="c9" id="h.n765s5jmkrq2"><span class="c2">Neural networks part 1</span></h4>
    <p class="c4"><span class="c7">2.6 </span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/neural-networks-1/&amp;sa=D&amp;ust=1574310063939000">http://cs231n.github.io/neural-networks-1/</a></span></p>
    <h4 class="c9" id="h.dhkwmbz4e6js"><span class="c2">Neural networks part 2</span></h4>
    <p class="c4"><span class="c7">2.7 </span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/neural-networks-2/&amp;sa=D&amp;ust=1574310063939000">http://cs231n.github.io/neural-networks-2/</a></span></p>
    <h4 class="c9" id="h.h8r53vq8ynkt"><span class="c2">Neural networks part 3</span></h4>
    <p class="c4"><span class="c7">2.8 </span><span class="c20"><a class="c15" href="https://www.google.com/url?q=http://cs231n.github.io/neural-networks-3/&amp;sa=D&amp;ust=1574310063940000">http://cs231n.github.io/neural-networks-3/</a></span></p>
    <h3 class="c22" id="h.j3nb1l2cuezs"><span class="c14">Slides</span></h3>
    <p class="c18"><span class="c1">Neural networks representation: non-linear hypotheses (Andrew Ng, ML wk 4 lecture 8)</span></p>
    <h2 class="c28" id="h.in94mxjxg73j"><span class="c13">Stanford lectures </span></h2>
    <p class="c4"><span class="c2">Lecture 4 back propagation </span></p>
    <p class="c4"><span class="c7">3.1</span><span class="c20"><a class="c15" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dd14TUNcbn1k%26t%3D1098s&amp;sa=D&amp;ust=1574310063941000">https://www.youtube.com/watch?v=d14TUNcbn1k&amp;t=1098s</a></span><span class="c1">&nbsp;</span></p>
    <h2 class="c21" id="h.x88b8s9lxwn5"><span class="c13">Additional resources</span></h2>
    <h4 class="c5" id="h.s6sc9sy44g3e"><span class="c2">create your own neural network</span></h4>
    <p class="c18"><span class="c1">playground.tensorflow.org</span></p>
    <h4 class="c5" id="h.qxl6s05ast2l"><span class="c2">k-nearest neighbors demo</span></h4>
    <p class="c18"><span class="c1">vision.stanford.edu</span></p>
    <h4 class="c5" id="h.wv6enpe6t7r1"><span class="c2">Linear Classification Demo</span></h4>
    <p class="c18"><span class="c20 c34"><a class="c15" href="https://www.google.com/url?q=http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/&amp;sa=D&amp;ust=1574310063943000">http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/</a></span></p>
    <h4 class="c5" id="h.xybo2n6f742e"><span class="c2">Code Words (not sure how it&rsquo;s connected exactly)</span></h4>
    <p class="c18"><span class="c1">codewords.recurse.com</span></p>
    <p class="c18 c26"><span class="c1"></span></p>
    <div>
        <p class="c4 c26"><span class="c1"></span></p>
    </div>
    
</body>

</html>